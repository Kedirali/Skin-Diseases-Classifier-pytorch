{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import logging\n",
    "import warnings\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from random import seed\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import models\n",
    "import pretrainedmodels as ptm\n",
    "import sklearn.metrics as skmet\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as nnF\n",
    "from imgaug import augmenters as iaa\n",
    "from torch.utils.data import DataLoader\n",
    "#from tensorboardX import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will run on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# On GPU or on CPU \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print('The model will run on', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset (data.Dataset):\n",
    "    \"\"\"\n",
    "    This is the standard way to implement a dataset pipeline in PyTorch. We need to extend the torch.utils.data.Dataset\n",
    "    class and implement the following methods: __len__, __getitem__ and the constructor __init__\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, imgs_path, labels, meta_data=None, transform=None):\n",
    "        \"\"\"\n",
    "        The constructor gets the images path and their respective labels and meta-data (if applicable).\n",
    "        In addition, you can specify some transform operation to be carry out on the images.\n",
    "        It's important to note the images must match with the labels (and meta-data if applicable). For example, the\n",
    "        imgs_path[x]'s label must take place on labels[x].\n",
    "        Parameters:\n",
    "        :param imgs_path (list): a list of string containing the image paths\n",
    "        :param labels (list) a list of labels for each image\n",
    "        :param meta_data (list): a list of meta-data regarding each image. If None, there is no information.\n",
    "        Defaul is None.\n",
    "        :param transform (torchvision.transforms.Compose): transform operations to be carry out on the images\n",
    "\n",
    "\n",
    "\n",
    "        The self parameter is a reference to the current instance of the class, and is used to access variables that belongs to the class.\n",
    "\n",
    "        It does not have to be named self , you can call it whatever you like, but it has to be the first parameter of any function in the class:\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.imgs_path = imgs_path\n",
    "        self.labels = labels\n",
    "        self.meta_data = meta_data\n",
    "\n",
    "        # if transform is None, we need to ensure that the PIL image will be transformed to tensor, otherwise we'll get\n",
    "        # an exception\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.ToTensor()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" This method just returns the dataset size \"\"\"\n",
    "        return len(self.imgs_path)\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        It gets the image, labels and meta-data (if applicable) according to the index informed in `item`.\n",
    "        It also performs the transform on the image.\n",
    "        :param item (int): an index in the interval [0, ..., len(img_paths)-1]\n",
    "        :return (tuple): a tuple containing the image, its label and meta-data (if applicable)\n",
    "        \"\"\"\n",
    "\n",
    "        image = Image.open(self.imgs_path[item]).convert(\"RGB\")\n",
    "\n",
    "        # Applying the transformations\n",
    "        image = self.transform(image)\n",
    "\n",
    "        img_id = self.imgs_path[item].split('/')[-1].split('.')[0]\n",
    "\n",
    "        if self.meta_data is None:\n",
    "            meta_data = []\n",
    "        else:\n",
    "            meta_data = self.meta_data[item]\n",
    "\n",
    "        if self.labels is None:\n",
    "            labels = []\n",
    "        else:\n",
    "            labels = self.labels[item]\n",
    "\n",
    "        return image, labels, meta_data, img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader (imgs_path, labels, meta_data=None, transform=None, batch_size=32, shuf=False, num_workers=0,\n",
    "                     pin_memory=True):\n",
    "    \"\"\"\n",
    "    This function gets a list of images path, their labels and meta-data (if applicable) and returns a DataLoader\n",
    "    for these files. You also can set some transformations using torchvision.transforms in order to perform data\n",
    "    augmentation. Lastly, params is a dictionary that you can set the following parameters:\n",
    "    batch_size (int): the batch size for the dataset. If it's not informed the default is 32\n",
    "    shuf (bool): set it true if wanna shuffe the dataset. If it's not informed the default is True\n",
    "    :param imgs_path (list): a list of string containing the images path\n",
    "    :param labels (list): a list of labels for each image\n",
    "    :param meta_data (list, optional): a list of meta-data regarding each image. If it's None, it means there's\n",
    "    no meta-data. Default is None\n",
    "    :param transform (torchvision.transforms, optional): use the torchvision.transforms.compose to perform the data\n",
    "    augmentation for the dataset. Alternatively, you can use the jedy.pytorch.utils.augmentation to perform the\n",
    "    augmentation. If it's None, none augmentation will be perform. Default is None\n",
    "    :param num_workers (int): the number of threads to be used in CPU. If the key is not informed or params = None, the\n",
    "    default value will be  4\n",
    "    :param pin_memory (bool): set it to True to Pytorch preload the images on GPU. If the key is not informed or\n",
    "    params = None, the default value will be True\n",
    "    :return (torch.utils.data.DataLoader): a dataloader with the dataset and the chose params\n",
    "    \"\"\"\n",
    "\n",
    "    dt = MyDataset(imgs_path, labels, meta_data, transform)\n",
    "    dl = DataLoader (dataset=dt, batch_size=batch_size, shuffle=shuf, num_workers=num_workers,\n",
    "                          pin_memory=pin_memory)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata(data_csv, replace_nan=None, cols_to_parse=None, replace_rules=None, save_path=None):\n",
    "    \"\"\"\n",
    "    This function parses the metadata within a csv/dataframe in order to transform string data in one_hot_encode\n",
    "    information. For example, if you have a column Gender that assume values as 'Female' or 'Male', this code will\n",
    "    create a new dataframe that replaces the column Gender to two columns: 'Female' and 'Male', in which will assume 1\n",
    "    or 0, depending on the gender.\n",
    "\n",
    "    :param data_csv (string or pandas.dataframe): the path for a csv or a dataframe already loaded\n",
    "    :param replace_nan (string or int or float or boolean or None): if you have NaN or missing data in your dataset you\n",
    "    can use this variable to replace them to a value. However, if you set it as None, the missing/NaN data will be\n",
    "    removed from the dataset. Default is None.\n",
    "    :param cols_to_parse (list, optional): a list of strings containing the column names to be parsed. If it's None,\n",
    "    none column will be parsed to hot encode. Default is None.\n",
    "    :param replace_rules (dict, optional): If you'd like to replace data in any column of your dataset, you can define\n",
    "    this rules here. For example, supose I have a column call 'A' that assume values as 1 or 'b'. If you'd like to\n",
    "    replace every incidence of 'b' to 2, you must do: replace_rules = {'A': {'b':2}}. Obviously, if you wanna insert\n",
    "    more rules for the same column or for a different one, you just need to follow the pattern. If None, none rule will\n",
    "    be carried out. Default is None.\n",
    "    :param save_path (string, optional): if you want to save the final dataframe, just set the path. If None, the\n",
    "    dataframe won't be save. Default is None.\n",
    "    :return: a parsed pandas.dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\" * 30)\n",
    "    print(\" Parsing the input csv ***\")\n",
    "\n",
    "    # Reading the csv\n",
    "    if isinstance(data_csv, str):\n",
    "        data = pd.read_csv(data_csv)\n",
    "    else:\n",
    "        data = data_csv\n",
    "\n",
    "    # Checking if we need to remove any possible NaN\n",
    "    if replace_nan is None:\n",
    "        data = data.dropna()\n",
    "    else:\n",
    "        data = data.fillna(replace_nan)\n",
    "\n",
    "\n",
    "    # If replace rules is true, we'll just replace the values by the given\n",
    "    # rules dictionary\n",
    "    if replace_rules is not None:\n",
    "        cols_rules_keys = list(replace_rules.keys())\n",
    "        for col in cols_rules_keys:\n",
    "            col_rules = list(replace_rules[col].keys())\n",
    "            col_values = list(replace_rules[col].values())\n",
    "            try:\n",
    "                data[col] = data[col].replace(col_rules, col_values)\n",
    "            except TypeError:\n",
    "                pass\n",
    "\n",
    "    # If cols_to_handle is None the function will return the data without do anything\n",
    "    new_col_names = list()\n",
    "    if cols_to_parse is not None:\n",
    "\n",
    "        for col in cols_to_parse:\n",
    "            # Getting the unique values\n",
    "            col_values = list(data[col].unique())\n",
    "\n",
    "            # Removing all elements containing the replace_nan\n",
    "            if replace_nan is not None:\n",
    "                try:\n",
    "                    col_values.remove(replace_nan)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "            # Sorting the values and saving them in new_col_names\n",
    "            col_values.sort()\n",
    "            new_col_names += col_values\n",
    "\n",
    "        # Now, let's train to compose the new dataframe:\n",
    "        # Getting the original col values and removing the handle ones\n",
    "        original_col_names = list(data.columns.values)\n",
    "        for c in cols_to_parse:\n",
    "            original_col_names.remove(c)\n",
    "            # Putting together the original and new columns. Now we have our final dataframe names\n",
    "        data_col_names = original_col_names + new_col_names\n",
    "        original_col_names = list(data.columns.values)\n",
    "\n",
    "        # Now, let's iterate through the old data and get all values for each sample, replacing\n",
    "        # for the one_hot encode if applicable\n",
    "        values = list()\n",
    "        for idx, row in data.iterrows():\n",
    "\n",
    "            row_dict = {c: 0 for c in data_col_names}\n",
    "            for col in original_col_names:\n",
    "                if col in data_col_names:\n",
    "                    row_dict[col] = row[col]\n",
    "                else:\n",
    "                    if replace_nan is not None:\n",
    "                        if row[col] == replace_nan:\n",
    "                            row_dict[row[col]] = 0\n",
    "                        else:\n",
    "                            row_dict[row[col]] = 1\n",
    "                    else:\n",
    "                        row_dict[row[col]] = 1\n",
    "\n",
    "            values.append(row_dict)\n",
    "\n",
    "        data = pd.DataFrame(values, columns=data_col_names)\n",
    "\n",
    "    if save_path is not None:\n",
    "        data.to_csv(save_path, columns=data_col_names, index=False)\n",
    "\n",
    "    print(\"- csv parsed!\")\n",
    "    print(\"=\" * 30)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_categorical_to_number (data_csv, col_target, col_target_number=None, save_path=None):\n",
    "    \"\"\"\n",
    "    This function converts a label from categorical to number. The values are converted to code in alphabetic ordem.\n",
    "    Example: for a set of labels ['A', 'B', 'C'] it converts to [0, 1, 2].\n",
    "    :param data_csv (string or pd.DataFrame): the path for a csv or a dataframe already loaded\n",
    "    :param col_target (string): the name of the target/label column\n",
    "    :param col_target_number (string): if you want to control the name of the column with the convert number, just set\n",
    "    the name here, otherwise it will set <col_target>_number\n",
    "    :param save_path (string): the path to save the result of this function. Default is None\n",
    "    return: it returns the same dataframe with an additional column called <col_target>_number or col_target_number\n",
    "    \"\"\"\n",
    "\n",
    "    # Loading the data_csv\n",
    "    if isinstance(data_csv, str):\n",
    "        data_csv = pd.read_csv(data_csv)\n",
    "\n",
    "    data_csv[col_target] = data_csv[col_target].astype('category')\n",
    "    if col_target_number is None:\n",
    "        data_csv[col_target + '_number'] = data_csv[col_target].cat.codes\n",
    "    else:\n",
    "        data_csv[col_target_number] = data_csv[col_target].cat.codes\n",
    "\n",
    "    if save_path is not None:\n",
    "        data_csv.to_csv(save_path, index=False)\n",
    "\n",
    "    return data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_frequency (data_csv, col_target, col_single_id, verbose=False):\n",
    "    \"\"\"\n",
    "    This function returns the frequency of each label in the dataset\n",
    "    :param data_csv (string or pd.DataFrame): the path for a csv or a dataframe already loaded\n",
    "    :param col_target (string): the name of the target/label column\n",
    "    :param col_single_id (string): the name any column that is present for all rows in the dataframe\n",
    "    :param verbose (boolean): a boolean to print or not the frequencies\n",
    "    return (pd.DataFrame): a dataframe containing the frequency of each label\n",
    "    \"\"\"\n",
    "\n",
    "    # Loading the data_csv\n",
    "    if isinstance(data_csv, str):\n",
    "        data_csv = pd.read_csv(data_csv)\n",
    "\n",
    "    data_ = data_csv.groupby([col_target])[col_single_id].count()\n",
    "    if (verbose):\n",
    "        print('### Data summary: ###')\n",
    "        print(data_)\n",
    "        print(\">> Total samples: {} <<\".format(data_.sum()))\n",
    "\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgTrainTransform:\n",
    "\n",
    "    def __init__(self, size=(224,224), normalization=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])):\n",
    "\n",
    "        self.normalization = normalization\n",
    "        self.aug = iaa.Sequential([\n",
    "            iaa.Sometimes(0.25, iaa.Affine(scale={\"x\": (1.0, 2.0), \"y\": (1.0, 2.0)})),\n",
    "            iaa.Scale(size),\n",
    "            iaa.Fliplr(1.0),\n",
    "            iaa.Flipud(1.0),  # vertically flip 20% of all images\n",
    "            iaa.Sometimes(1.0, iaa.Affine(rotate=(-90, 90), mode='symmetric')),\n",
    "            iaa.Sometimes(1.0, iaa.Affine(rotate=(-180, 180), mode='symmetric')),\n",
    "            iaa.Sometimes(1.0, iaa.Affine(rotate=(-270, 270), mode='symmetric')),\n",
    "            iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 1.5))),\n",
    "\n",
    "            # noise\n",
    "            iaa.Sometimes(0.1,\n",
    "                          iaa.OneOf([\n",
    "                              iaa.Dropout(p=(0, 0.05)),\n",
    "                              iaa.CoarseDropout(0.02, size_percent=0.25)\n",
    "                          ])),\n",
    "\n",
    "            iaa.Sometimes(0.25,\n",
    "                          iaa.OneOf([\n",
    "                              iaa.Add((-15, 15), per_channel=0.5), # brightness\n",
    "                              iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
    "                          ])),\n",
    "\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = self.aug.augment_image(np.array(img)).copy()\n",
    "        transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(self.normalization[0], self.normalization[1]),\n",
    "        ])\n",
    "        return transforms(img)\n",
    "\n",
    "\n",
    "class ImgEvalTransform:\n",
    "\n",
    "    def __init__(self, size=(224,224), normalization=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])):\n",
    "\n",
    "        self.normalization = normalization\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(self.size),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(self.normalization[0], self.normalization[1]),\n",
    "        ])\n",
    "        return transforms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(ind, N=None):\n",
    "    \"\"\"\n",
    "    This function binarizes a vector (one hot enconding).\n",
    "    For example:\n",
    "    Input: v = [1,2,3]\n",
    "    Output: v = [[1,0,0;\n",
    "                0,1,0;\n",
    "                0,0,1]]\n",
    "\n",
    "    :param ind (numpy array): an numpy array 1 x n in which each position is a label\n",
    "    :param N (int, optional): the number of indices. If None, the code get is from the shape. Default is None.\n",
    "\n",
    "    :return (numpy.array): the one hot enconding array n x N\n",
    "    \"\"\"\n",
    "\n",
    "    ind = np.asarray(ind)\n",
    "    if ind is None:\n",
    "        return None\n",
    "\n",
    "    if N is None:\n",
    "        N = ind.max() + 1\n",
    "\n",
    "    return (np.arange(N) == ind[:, None]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_dim (lab_real, lab_pred, mode='labels'):\n",
    "    \"\"\"\n",
    "    This  function checks if y_real and y_pred are 1-d or 2-d. If mode is 'labels', this function returns an 1-d array\n",
    "    ints, for ex: [0, 0, 1, 1, 2], in which each number is a label. If mode is 'scores', this function returns an 2-d\n",
    "    array following the one hot encoding methos. For ex: [[0,0,0], [0,0,0], [0,1,0], [0,1,0], [0,0,1]]\n",
    "\n",
    "    :param lab_real(1d or 2d n.array): the data real labels\n",
    "    :param lab_pred(1d or 2d n.array): the predictions returned by the model\n",
    "    :param mode (string, optional): the operation mode described above. Default is 'labels'\n",
    "    :return (np.array, np.array): returns the lab_real and lab_pred transformed\n",
    "    \"\"\"\n",
    "    if mode == 'labels':\n",
    "        if lab_real.ndim == 2:\n",
    "            lab_real = lab_real.argmax(axis=1)\n",
    "        if lab_pred.ndim == 2:\n",
    "            lab_pred = lab_pred.argmax(axis=1)\n",
    "\n",
    "    elif mode == 'scores':\n",
    "        if lab_real.ndim == 1:\n",
    "            lab_real = one_hot_encoding(lab_real)\n",
    "        if lab_pred.ndim == 1:\n",
    "            lab_pred = one_hot_encoding(lab_pred)\n",
    "\n",
    "    else:\n",
    "        raise Exception ('There is no mode called {}. Please, choose between score or labels'.format(mode))\n",
    "\n",
    "    return lab_real, lab_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AVGMetrics (object):\n",
    "    \"\"\"\n",
    "        This is a simple class to control the AVG for a given value. It's used to control loss and accuracy for start\n",
    "        and evaluate partition\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.sum_value = 0\n",
    "        self.avg = 0\n",
    "        self.count = 0\n",
    "        self.values = []\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.avg\n",
    "\n",
    "    def update(self, val):\n",
    "        self.values.append(val)\n",
    "        self.sum_value += val\n",
    "        self.count += 1\n",
    "        self.avg = self.sum_value / float(self.count)\n",
    "\n",
    "    def print (self):\n",
    "        print('\\nsum_value: ', self.sum_value)\n",
    "        print('count: ', self.count)\n",
    "        print('avg: ', self.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy (lab_real, lab_pred, verbose=False):\n",
    "    \"\"\"\n",
    "    Computess the accuracy. Both lab_real and lab_pred can be a labels array or and a array of\n",
    "    scores (one hot encoding) for each class.\n",
    "\n",
    "    :param lab_real(np.array): the data real labels\n",
    "    :param lab_pred(np.array): the predictions returned by the model\n",
    "    :param verbose(bool, optional): if you'd like to print the accuracy. Dafault is False.\n",
    "    :return (float): the accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Checkin the array dimension\n",
    "    lab_real, lab_pred = _check_dim (lab_real, lab_pred, mode='labels')\n",
    "\n",
    "    acc = skmet.accuracy_score(lab_real, lab_pred)\n",
    "\n",
    "    if verbose:\n",
    "        print('- Accuracy - {:.3f}'.format(acc))\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainHistory:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.val_loss = list()\n",
    "        self.val_acc = list()\n",
    "        self.train_loss = list()\n",
    "        self.train_acc = list()\n",
    "        \n",
    "    \n",
    "    def update (self, loss_train, loss_val, acc_train, acc_val):\n",
    "        \"\"\"\n",
    "        This function appends a new value to the loss/train loss and acc. These values are stored by epoch\n",
    "        :param loss_train: the train loss of the ith epoch\n",
    "        :param loss_val: the val loss of the ith epoch\n",
    "        :param acc_train: the train accuracy of the ith epoch\n",
    "        :param acc_val: the val accuracy of the ith epoch\n",
    "        \"\"\"\n",
    "\n",
    "        self.train_loss.append(loss_train)\n",
    "        self.val_loss.append(loss_val)\n",
    "        self.train_acc.append(acc_train)\n",
    "        self.val_acc.append(acc_val)\n",
    "\n",
    "\n",
    "    def save (self, folder_path):\n",
    "        \"\"\"\n",
    "        This function saves the loss and accuracy history as csv files\n",
    "        :param folder_path: a string with the base folder path\n",
    "        \"\"\"\n",
    "\n",
    "        path = os.path.join(folder_path, 'history')\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        print (\"Saving history CSVs in {}\".format(path))\n",
    "\n",
    "        np.savetxt(os.path.join(path, \"train_loss.csv\"), np.asarray(self.train_loss), fmt='%.3f', delimiter=',')\n",
    "        np.savetxt(os.path.join(path, \"val_loss.csv\"), np.asarray(self.val_loss), fmt='%.3f', delimiter=',')\n",
    "\n",
    "        np.savetxt(os.path.join(path, \"train_acc.csv\"), np.asarray(self.train_acc), fmt='%.3f', delimiter=',')\n",
    "        np.savetxt(os.path.join(path, \"val_acc.csv\"), np.asarray(self.val_acc), fmt='%.3f', delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "    def save_plot (self, folder_path):\n",
    "        \"\"\"\n",
    "        This function saves a plot of the loss and accuracy history\n",
    "        :param folder_path: a string with the base folder path\n",
    "        \"\"\"\n",
    "\n",
    "        path = os.path.join(folder_path, 'history')\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        epochs = [i + 1 for i in range(len(self.train_loss))]\n",
    "\n",
    "        print(\"Saving history plots in {}\".format(path))\n",
    "\n",
    "        plt.plot(epochs, self.train_loss, color='r', linestyle='solid')\n",
    "        plt.plot(epochs, self.val_loss, color='b', linestyle='solid')\n",
    "        plt.grid(color='black', linestyle='dotted', linewidth=0.7)\n",
    "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training Loss\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(path, \"loss_history.jpg\"), dpi=300)\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        plt.plot(epochs, self.train_acc, color='r', linestyle='solid')\n",
    "        plt.plot(epochs, self.val_acc, color='b', linestyle='solid')\n",
    "        plt.grid(color='black', linestyle='dotted', linewidth=0.7)\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Training Accuracy\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(path, \"acc_history.jpg\"), dpi=200)\n",
    "\n",
    "        plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix (lab_real, lab_pred, normalize=True):\n",
    "    \"\"\"\n",
    "    This function computes the confusion matrix. Both lab_real and lab_pred can be a labels array or and a array of\n",
    "    scores (one hot encoding) for each class.\n",
    "\n",
    "    :param lab_real(np.array): the data real labels\n",
    "    :param lab_pred(np.array): the predictions returned by the model\n",
    "    :param class_names (list): the name of each label. For example: ['l1','l2']. If you pass a list with a different\n",
    "    number of labels that provided in lad_pred or real, you're gonna have an exception. If None, the labels will not\n",
    "    be considered. Default is None.\n",
    "    :param normalize (bool, optional): set it True if you'd like to normalize the cm. Default is False.\n",
    "    :return (2d np array: an np array containing the confusion matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Checkin the array dimension\n",
    "    lab_real, lab_pred = _check_dim(lab_real, lab_pred, mode='labels')\n",
    "\n",
    "    cm = skmet.confusion_matrix(lab_real, lab_pred)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_matrix(cm, class_names, normalize=True, save_path=None, title='Confusion matrix', cmap=plt.cm.GnBu):\n",
    "    \"\"\"\n",
    "    This function makes a plot for a given confusion matrix. It can plots either the real or normalized one.\n",
    "    Most of this code is provided on:\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "    Please, refers there for any further reference.\n",
    "\n",
    "    :param cm (np.array): An m x m np array containing the confusion matrix\n",
    "    :param class_names (list): a list with the class labels. Ex:['A', 'B'], if you have 2 labels\n",
    "    :param normalize (bool, optional): set it True if you'd like to normalize the cm. Default is True.\n",
    "    :param save_path (string, optional): if you'd like to save your plot instead of show it on the screen, you need to\n",
    "    provide the full path (including image name and format) to do so. Ex: /home/user/cm.png. If None, the plot is not\n",
    "    save but showed in the screen. Default is None.\n",
    "    :param title (string, optional): the plot's title. Default is 'Confusion matrix'\n",
    "    :param cmap (plt.cm.color, option): a color pallete provided by pyplot. Default is GnBu.\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=0)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if isinstance(save_path, str):\n",
    "        plt.savefig(save_path, dpi=200)\n",
    "        plt.clf()\n",
    "    elif save_path:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_report (lab_real, lab_pred, class_names=None, verbose=False, output_dict=False):\n",
    "    \"\"\"\n",
    "    Computes the precision, recall, F1 score and support for each class. Both lab_real and lab_pred can be a labels\n",
    "    array or and a array of scores (one hot encoding) for each class.\n",
    "\n",
    "    :param lab_real (np.array): the data real labels\n",
    "    :param lab_pred (np.array): the predictions returned by the model\n",
    "    :param class_names (list): the name of each label. For example: ['l1','l2']. If you pass a list with a different\n",
    "    number of labels that provided in lad_pred or real, you're gonna have an exception. If None, the labels will not\n",
    "    be considered. Default is None.\n",
    "    :return (string): a string containing the repost regarding each metric\n",
    "    \"\"\"\n",
    "\n",
    "    # Checking the array dimension\n",
    "    lab_real, lab_pred = _check_dim(lab_real, lab_pred, mode='labels')\n",
    "\n",
    "    report = skmet.classification_report(lab_real, lab_pred, target_names=class_names, output_dict=output_dict)\n",
    "\n",
    "    if verbose:\n",
    "         print(report)\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_from_csv (csv, class_names=None, conf_mat=False, conf_mat_path=None, verbose=True):\n",
    "\n",
    "    if isinstance(csv, str):\n",
    "        data = pd.read_csv(csv)\n",
    "    else:\n",
    "        data = csv\n",
    "\n",
    "    if class_names is None:\n",
    "        class_names = data.columns.values[1:]\n",
    "\n",
    "    class_names_dict = {name: pos for pos, name in enumerate(class_names)}\n",
    "    preds = data[class_names].values\n",
    "\n",
    "    try:\n",
    "        labels_str = data['REAL'].values\n",
    "    except KeyError:\n",
    "        print (\"Warning: There is no ground truth in this file! The code will return None\")\n",
    "        return None\n",
    "\n",
    "    labels = [class_names_dict[lstr] for lstr in labels_str]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    acc = accuracy(labels, preds)\n",
    "    rep =  precision_recall_report(labels, preds, class_names, output_dict=True)\n",
    "    loss = skmet.log_loss(labels, preds)\n",
    "\n",
    "    if conf_mat:\n",
    "        plt.figure()\n",
    "        cm = conf_matrix(labels, preds, normalize=True)\n",
    "        if conf_mat_path is None:\n",
    "            p = \"./conf.jpg\"\n",
    "        else:\n",
    "            p = conf_mat_path\n",
    "        plot_conf_matrix(cm, class_names, title='Confusion matrix', cmap=plt.cm.GnBu, save_path=p)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"-\" * 50)\n",
    "        print(\"- Metrics:\")\n",
    "        print(\"- Loss: {:.3f}\".format(loss))\n",
    "        print(\"- Accuracy: {:.3f}\".format(acc))\n",
    "        print(\"- Classification Report: {:.3f}\".format(rep))\n",
    "\n",
    "    return acc, rep, loss, fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model (model, folder_path, epoch, opt_fn, loss_fn, is_best, multi_gpu=False, verbose=False):\n",
    "    \"\"\"\n",
    "    This function saves the parameters of a model. It saves the last and best model (if it's the best).\n",
    "\n",
    "    :param model (nn.Model): the model you wanna save the parameters\n",
    "    :param folder_path (string): the folder you wanna save the checkpoints\n",
    "    :param name_last (string): the file's name of the last checkpoint. Considers using epoch in the name\n",
    "    :param name_best (bool, optional): the file's name of the best checkpoint. If it's False, it means this checkpoint\n",
    "    :param verbose (bool, optional): If you'd like to print information on the screen. Default is False.\n",
    "    is not the best one. Default is false.\n",
    "    \"\"\"\n",
    "\n",
    "    last_check_path = os.path.join(folder_path, 'last-checkpoint')\n",
    "    best_check_path = os.path.join(folder_path, 'best-checkpoint')\n",
    "\n",
    "    if not os.path.exists(last_check_path):\n",
    "        if verbose:\n",
    "            print ('last-checkpoint folder does not exist. I am creating it!')\n",
    "        os.mkdir(last_check_path)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print ('last-checkpoint folder exist! Perfect, I will just use it.')\n",
    "\n",
    "    if not os.path.exists(best_check_path):\n",
    "        if verbose:\n",
    "            print('best-checkpoint folder does not exist. I am creating it!')\n",
    "        os.mkdir(best_check_path)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('best-checkpoint folder exist! Perfect, I will just use it.')\n",
    "\n",
    "    info_to_save = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.module.state_dict() if multi_gpu else model.state_dict(),\n",
    "        'optimizer_state_dict': opt_fn.state_dict(),\n",
    "        'loss': loss_fn,\n",
    "    }\n",
    "\n",
    "    torch.save(info_to_save, os.path.join(last_check_path, \"last-checkpoint.pth\"))\n",
    "\n",
    "    if is_best:\n",
    "        torch.save(info_to_save, os.path.join(best_check_path, 'best-checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model (checkpoint_path, model, opt_fn=None, loss_fn=None, epoch=None):\n",
    "    \"\"\"\n",
    "    This function loads a model from a given checkpoint.\n",
    "\n",
    "    :param checkpoint_path (string): the full path to de checkpoint\n",
    "    :param model (nn.Model): the model that you wanna load the parameters\n",
    "    :return (nn.Model): the loaded model\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise Exception (\"The {} does not exist!\".format(checkpoint_path))\n",
    "\n",
    "    ckpt = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "    if opt_fn is not None and loss_fn is not None:\n",
    "        opt_fn.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "        epoch = ckpt['epoch']\n",
    "        loss_fn = ckpt['loss']\n",
    "        return model, opt_fn, loss_fn, epoch\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_k_folder_csv (data_csv, col_target, save_path=None, k_folder=10, seed_number=None):\n",
    "    \"\"\"\n",
    "    This function gets a csv/dataframe and creates a new column called 'folder' that represents the k-folder cross\n",
    "    validation\n",
    "    :param data_csv (string or pd.DataFrame): the path for a csv or a dataframe already loaded\n",
    "    :param col_target (string): the name of the target/label column\n",
    "    :param k_folder(int): the number of folders for the cross validation\n",
    "    :param save_path (string): the path to save the result of this function. Default is None\n",
    "    :param seed_number (number, optional): a seed number to guarantee reproducibility\n",
    "    return (pd.DataFrame): the dataframe with the new column\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\" * 30)\n",
    "    print(\"- Generating the {}-foders***\".format(k_folder))\n",
    "\n",
    "    # Loading the data_csv\n",
    "    if isinstance(data_csv, str):\n",
    "        data_csv = pd.read_csv(data_csv)\n",
    "\n",
    "    skf = StratifiedKFold(k_folder, True, seed_number)\n",
    "    target = data_csv[col_target]\n",
    "    data_csv['folder'] = None\n",
    "    for folder_number, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(target)), target)):\n",
    "        data_csv.loc[val_idx, 'folder'] = folder_number + 1\n",
    "\n",
    "    if save_path is not None:\n",
    "        data_csv.to_csv(save_path, index=False)\n",
    "\n",
    "    print(\" Done!\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    return data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      " Parsing the input csv ***\n",
      "- csv parsed!\n",
      "==============================\n",
      "==============================\n",
      "- Generating the 10-foders***\n",
      " Done!\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = \"E:/Skin_App/Drive\"\n",
    "\n",
    "\n",
    "data = parse_metadata (os.path.join(BASE_PATH, \"train_meta_data.csv\"), replace_nan=\"missing\",\n",
    "           cols_to_parse=['Gender', 'Anatomical_Site'], replace_rules={\"Approximated_Age\": {\"missing\": 0}})\n",
    "\n",
    "\n",
    "data = split_k_folder_csv(data, \"Diagnosis\", save_path=None, k_folder=10, seed_number=8)\n",
    "data = label_categorical_to_number (data, \"Diagnosis\", col_target_number=\"Diagnosis_number\")\n",
    "data_test = data[ data['folder'] == 10]\n",
    "data_train = data[ data['folder'] != 10]\n",
    "data_train.to_csv(os.path.join(BASE_PATH, \"ked_parsed_train.csv\"), index=False)\n",
    "data_test.to_csv(os.path.join(BASE_PATH, \"ked_parsed_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "\n",
    "    def __init__(self, metrics_names, class_names=None, options=None):\n",
    "        \"\"\"\n",
    "        Construction method. You must inform the metrics you'd like to compute. Optionally, you may set some options \n",
    "        and the classes names. Each parameter is better described bellow:\n",
    "        \n",
    "        :param metrics_name (list, tuple or string): it's the variable that receives the metrics you'd like to compute.\n",
    "        The following metrics are available: \"accuracy\", \"conf_matrix\", \"plot_conf_matrix\", \"precision_recall_report\". \n",
    "        \n",
    "        To understand them, please, go to jedy.utils.classification_metrics.py.\n",
    "        \n",
    "        You should pass one or more of these metrics in a list or a tuple, \n",
    "        for ex: m = [\"accuracy\", \"conf_matrix\"]. If you'd like to compute all of them, just set it as 'all', i.e., \n",
    "        m = 'all'\n",
    "        \n",
    "        Important: if you'd like to compute either 'plot_conf_matrix' or 'auc_and_roc_curve', you must inform the\n",
    "        class_names. If not, you'll get an exception. The remaining metrics, except 'accuracy', also use the class_name,\n",
    "        however, it's not demanded for them\n",
    "        \n",
    "        :param class_names (list, tuple): a list or tuple containing the classes names in the same order you use in the\n",
    "        label. For ex: ['C1', 'C2']\n",
    "\n",
    "        :param options (dict): this is a dict containing some options to compute the metrics. The following options are\n",
    "        available:\n",
    "        - For all:\n",
    "            - save_all_path: a string with the path to save all metrics and images. In this case, the conf matrix will be\n",
    "            called by conf_mat.jpg\n",
    "\n",
    "\n",
    "        - For 'conf_matrix': \n",
    "            - 'normalize_conf_matrix' (bool): inform if you'd like to normalize the confusion matrix\n",
    "        \n",
    "        - For 'plot_conf_matrix':\n",
    "            - 'save_path_conf_matrix' (string): the complete file path if you'd like to save instead show the plot\n",
    "            - 'normalize_conf_matrix' (bool): inform if you'd like to normalize the confusion matrix\n",
    "            - 'title_conf_matrix' (string): the plot's title\n",
    "\n",
    "        - For 'save_scores':\n",
    "            - 'save_path_scores' (string): the complete file path if to save the scores\n",
    "            - 'pred_name_scores' (string): the names of the predictions .csv. If it's not informed, it's going to be\n",
    "            predictions.csv\n",
    "            \n",
    "        For more information about the options, please, refers to jedy.utils.classification_metrics.py\n",
    "         \n",
    "        \"\"\"\n",
    "        self.metrics_names = metrics_names\n",
    "        self.metrics_values = dict()        \n",
    "        self.options = options\n",
    "        \n",
    "        self.pred_scores = None\n",
    "        self.label_scores = None\n",
    "        self.img_names = None\n",
    "        \n",
    "        self.class_names = class_names\n",
    "\n",
    "\n",
    "    def compute_metrics (self):\n",
    "        \"\"\"\n",
    "        This method computes all metrics defined in metrics_name.\n",
    "        :return: it saves in self.metric_values all computed metrics\n",
    "        \"\"\"\n",
    "\n",
    "        save_all_path = None\n",
    "        # Checking if save_all is informed\n",
    "        if self.options is not None:\n",
    "            if \"save_all_path\" in self.options.keys():\n",
    "                # Checking if the folder doesn't exist. If True, we must create it.\n",
    "                if not os.path.isdir(self.options[\"save_all_path\"]):\n",
    "                    os.mkdir(self.options[\"save_all_path\"])\n",
    "                save_all_path = self.options[\"save_all_path\"]\n",
    "\n",
    "        if self.metrics_names is None:\n",
    "            return None\n",
    "        \n",
    "        if self.metrics_names == \"all\":\n",
    "            self.metrics_names = [\"accuracy\", \"conf_matrix\", \"plot_conf_matrix\", \"precision_recall_report\"]\n",
    "        \n",
    "        \n",
    "        for mets in self.metrics_names:\n",
    "            if mets == \"accuracy\":\n",
    "                self.metrics_values[\"accuracy\"] = accuracy(self.label_scores, self.pred_scores)\n",
    "\n",
    "            \n",
    "            elif mets == \"conf_matrix\":\n",
    "                \n",
    "                # Checking the options\n",
    "                normalize = True\n",
    "                if self.options is not None:\n",
    "                    if \"normalize_conf_matrix\" in self.options.keys():\n",
    "                        normalize = self.options[\"normalize_conf_matrix\"]\n",
    "                \n",
    "                self.metrics_values[\"conf_matrix\"] = conf_matrix(self.label_scores, self.pred_scores, normalize)\n",
    "            elif mets == \"plot_conf_matrix\":\n",
    "                \n",
    "                # Checking if the class names are defined\n",
    "                if self.class_names is None:\n",
    "                    raise Exception (\"You are trying to plot the confusion matrix without defining the classes name\")\n",
    "                \n",
    "                # Checking the options\n",
    "                save_path = None\n",
    "                normalize = True\n",
    "                title = \"Confusion Matrix\"   \n",
    "                \n",
    "                if self.options is not None:\n",
    "                    if save_all_path is not None:\n",
    "                        save_path = os.path.join(save_all_path, \"confusion_matrix.jpg\")\n",
    "                    if \"save_path_conf_matrix\" in self.options.keys():\n",
    "                        save_path = self.options[\"save_path_conf_matrix\"]\n",
    "                    if \"normalize_conf_matrix\" in self.options.keys():\n",
    "                        normalize = self.options[\"normalize_conf_matrix\"]\n",
    "                    if \"title_conf_matrix\" in self.options.keys():\n",
    "                        title = self.options[\"title_conf_matrix\"]\n",
    "                        \n",
    "                if \"conf_matrix\" in self.metrics_values.keys():\n",
    "                    cm = self.metrics_values[\"conf_matrix\"]\n",
    "                else:\n",
    "                    cm = conf_matrix(self.label_scores, self.pred_scores, normalize)\n",
    "                \n",
    "                plot_conf_matrix(cm, self.class_names, normalize, save_path, title)\n",
    "                \n",
    "                \n",
    "            elif mets == \"precision_recall_report\":\n",
    "                \n",
    "                self.metrics_values[\"precision_recall_report\"] = precision_recall_report(self.label_scores,\n",
    "                                                                                              self.pred_scores,\n",
    "                                                                                              self.class_names)\n",
    "\n",
    "            \n",
    "    def print (self):\n",
    "        \"\"\"\n",
    "        This method just prints the metrics on the screen\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.metrics_names is None:\n",
    "            print (\"Since metrics name is None, there is no metric to print\")\n",
    "            \n",
    "        else:        \n",
    "            for met in self.metrics_values.keys():\n",
    "                if met == \"loss\":\n",
    "                    print ('- Loss: {:.3f}'.format(self.metrics_values[met]))\n",
    "                elif met == \"accuracy\":\n",
    "                    print ('- Accuracy: {:.3f}'.format(self.metrics_values[met]))\n",
    "                elif met == \"conf_matrix\":\n",
    "                    print('- Confusion Matrix: \\n{}'.format(self.metrics_values[met]))\n",
    "                elif met == \"precision_recall_report\":\n",
    "                    print('- Precision and Recall report: \\n{}'.format(self.metrics_values[met]))\n",
    "\n",
    "    def add_metric_value (self, value_name, value):\n",
    "        \"\"\"\n",
    "        Adding a new value from a external source into the metrics\n",
    "        :param value_name (string): the key for the dict\n",
    "        :param value: the value to be saved in the self.metrics_values\n",
    "        \"\"\"\n",
    "        self.metrics_values[value_name] = value\n",
    "\n",
    "\n",
    "    def update_scores (self, label_batch, pred_batch, img_name_batch=None):\n",
    "        \"\"\"\n",
    "        The evaluation is made using batchs. So, every batch we get just a piece of the prediction. This method\n",
    "        concatenate all prediction and labels in order to compute the metrics\n",
    "        :param pred (np.array): an array containing part of the predictions outputed by the model\n",
    "        :param label (np.array): an array contaning the true labels\n",
    "        \"\"\"\n",
    "\n",
    "        if self.label_scores is None and self.pred_scores is None:\n",
    "            self.label_scores = label_batch\n",
    "            self.pred_scores = pred_batch\n",
    "            self.img_names = img_name_batch\n",
    "        else:\n",
    "            if pred_batch is not None:\n",
    "                self.pred_scores = np.concatenate((self.pred_scores, pred_batch))\n",
    "            if label_batch is not None:\n",
    "                self.label_scores = np.concatenate((self.label_scores, label_batch))\n",
    "            if img_name_batch is not None:\n",
    "                self.img_names = np.concatenate((self.img_names, img_name_batch))\n",
    "\n",
    "\n",
    "    def save_metrics (self, folder_path, name=\"metrics.txt\"):\n",
    "        \"\"\"\n",
    "        This method saves the computed metrics\n",
    "        :param folder_path (string): the folder you'd like to save the metrics\n",
    "        :param name (string): the file name. Default is metrics.txt\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.metrics_names is None:\n",
    "            print (\"Since metrics name is None, there is no metric to save\")\n",
    "            \n",
    "        else:        \n",
    "            with open(os.path.join(folder_path, name), \"w\") as f:\n",
    "    \n",
    "                f.write(\"- METRICS REPORT -\\n\\n\")\n",
    "    \n",
    "                for met in self.metrics_values.keys():\n",
    "                    if met == \"loss\":\n",
    "                        f.write('- Loss: {:.3f}\\n'.format(self.metrics_values[met]))\n",
    "                    elif met == \"accuracy\":\n",
    "                        f.write('- Accuracy: {:.3f}\\n'.format(self.metrics_values[met]))\n",
    "                    elif met == \"conf_matrix\":\n",
    "                        f.write('- Confusion Matrix: \\n{}\\n'.format(self.metrics_values[met]))\n",
    "                    elif met == \"precision_recall_report\":\n",
    "                        f.write('- Precision and Recall report: \\n{}\\n'.format(self.metrics_values[met]))\n",
    "\n",
    "\n",
    "    def save_scores (self, folder_path=None, pred_name=\"predictions.csv\"):\n",
    "        \"\"\"\n",
    "        This method saves the concatenated scores in the disk\n",
    "        :param folder_path (string): the folder you'd like to save the scores\n",
    "        :param pred_name (string): the predictions' score file name. Default is predictions.csv\n",
    "        :param labels_name (string): the labels' score file name. Default is labels.csv\n",
    "        \"\"\"\n",
    "\n",
    "        if folder_path is not None:\n",
    "            # Checking if the folder doesn't exist. If True, we must create it.\n",
    "            if not os.path.isdir(folder_path):\n",
    "                os.mkdir(folder_path)\n",
    "        elif self.options is not None:\n",
    "            if \"save_all_path\" in self.options.keys():\n",
    "                folder_path = self.options[\"save_all_path\"]\n",
    "            elif \"save_path_scores\" in self.options.keys():\n",
    "                folder_path = self.options[\"save_path_scores\"]\n",
    "            else:\n",
    "                raise (\"The options doesnt have any folder to save the scores\")\n",
    "\n",
    "            if 'pred_name_scores' in self.options.keys():\n",
    "                pred_name = self.options['pred_name_scores']\n",
    "        else:\n",
    "            raise (\"You must set the path to save the score eithe in options or in folder_path parameter\")\n",
    "\n",
    "\n",
    "        # Getting the list of classications and predict labels\n",
    "        if self.class_names is not None:\n",
    "            if self.label_scores is not None:\n",
    "                real_labels = [self.class_names[int(l)] for l in self.label_scores]\n",
    "                real_labels = np.asarray(real_labels)\n",
    "                real_labels = real_labels.reshape(real_labels.shape[0], 1)\n",
    "\n",
    "            if self.img_names is not None:\n",
    "                img_names = np.asarray(self.img_names)\n",
    "                img_names = img_names.reshape(img_names.shape[0], 1)\n",
    "\n",
    "            pred_labels = [self.class_names[ps.argmax()] for ps in self.pred_scores]\n",
    "            pred_labels = np.asarray(pred_labels)\n",
    "            pred_labels = pred_labels.reshape(pred_labels.shape[0], 1)\n",
    "        else:\n",
    "            raise (\"You need to inform the class names to use this function\")\n",
    "\n",
    "        if self.img_names is not None and self.label_scores is not None:\n",
    "            both_data = np.concatenate((img_names, real_labels, pred_labels, self.pred_scores), axis=1)\n",
    "            cols = ['image', 'REAL', 'PRED', *self.class_names]\n",
    "        elif self.img_names is None and self.label_scores is not None:\n",
    "            both_data = np.concatenate((real_labels, pred_labels, self.pred_scores), axis=1)\n",
    "            cols = ['REAL', 'PRED', *self.class_names]\n",
    "        elif self.img_names is not None and self.label_scores is None:\n",
    "            both_data = np.concatenate((img_names, pred_labels, self.pred_scores), axis=1)\n",
    "            cols = ['image', 'PRED', *self.class_names]\n",
    "        else:\n",
    "            both_data = np.concatenate((real_labels, pred_labels, self.pred_scores), axis=1)\n",
    "            cols = ['REAL', 'PRED', *self.class_names]\n",
    "\n",
    "        df = pd.DataFrame(both_data, columns=cols)\n",
    "        print (\"Saving the scores in {}\".format(folder_path))\n",
    "\n",
    "        df.to_csv(os.path.join(folder_path, pred_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMobilenet (nn.Module):\n",
    "\n",
    "    def __init__(self, mobilenet, num_class, freeze_conv=False, p_dropout=0.5,\n",
    "                 comb_method=None, comb_config=None, n_feat_conv=1280):\n",
    "\n",
    "        super(MyMobilenet, self).__init__()\n",
    "\n",
    "        _n_meta_data = 0\n",
    "        if comb_method is not None:\n",
    "            \n",
    "            if comb_method == 'concat':\n",
    "                if not isinstance(comb_config, int):\n",
    "                    raise Exception(\"comb_config must be int for 'concat' method\")\n",
    "                _n_meta_data = comb_config\n",
    "                self.comb = 'concat'\n",
    "            else:\n",
    "                raise Exception(\"There is no comb_method called \" + comb_method + \". Please, check this out.\")\n",
    "        else:\n",
    "            self.comb = None\n",
    "\n",
    "        self.features = nn.Sequential(*list(mobilenet.children())[:-1])\n",
    "        # freezing the convolution layers\n",
    "        if freeze_conv:\n",
    "            for param in self.features.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Linear(n_feat_conv + _n_meta_data, num_class)\n",
    "\n",
    "    def forward(self, img, meta_data=None):\n",
    "\n",
    "        # Checking if when passing the metadata, the combination method is set\n",
    "        if meta_data is not None and self.comb is None:\n",
    "            raise Exception(\"There is no combination method defined but you passed the metadata to the model!\")\n",
    "        if meta_data is None and self.comb is not None:\n",
    "            raise Exception(\"You must pass meta_data since you're using a combination method!\")\n",
    "\n",
    "        x = self.features(img)\n",
    "        x = x.mean([2, 3])\n",
    "\n",
    "        if self.comb == 'concat':\n",
    "            x = x.view(x.size(0), -1) # flatting\n",
    "            x = torch.cat([x, meta_data], dim=1) # concatenation\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MODELS = ['mobilenet']\n",
    "\n",
    "\n",
    "def set_model (model_name, num_class,comb_method=None, comb_config=None, \n",
    "               pretrained=True,freeze_conv=False):\n",
    "\n",
    "    if pretrained:\n",
    "        pre_torch = True\n",
    "    else:\n",
    "        pre_torch = False\n",
    "\n",
    "    if model_name not in _MODELS:\n",
    "        raise Exception(\"The model {} is not available!\".format(model_name))\n",
    "\n",
    "    model = None\n",
    "    if model_name == 'mobilenet':\n",
    "        model = MyMobilenet(models.mobilenet_v2(pretrained=pre_torch), num_class, freeze_conv,\n",
    "                            comb_method=comb_method, comb_config=comb_config)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _config_logger(save_path, file_name):\n",
    "    \"\"\"\n",
    "        Internal function to configure the logger\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    logger = logging.getLogger(\"Train-Logger\")\n",
    "    # Checking if the folder logs doesn't exist. If True, we must create it.\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    logger_filename = os.path.join(save_path, f\"{file_name}_{str(time.time()).replace('.','')}.log\")\n",
    "    fhandler = logging.FileHandler(filename=logger_filename, mode='a')\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    logger.addHandler(fhandler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def _train_epoch (model, optimizer, loss_fn, data_loader, c_epoch, t_epoch, device=None):\n",
    "    \"\"\"\n",
    "    This function trains an epoch of the dataset, that is, it goes through all dataset batches once.\n",
    "    :param model (torch.nn.Module): a module to be trained\n",
    "    :param optimizer (torch.optim.optim): an optimizer to fit the model\n",
    "    :param loss_fn (torch.nn.Loss): a loss function to evaluate the model prediction\n",
    "    :param data_loader (torch.utils.DataLoader): a dataloader containing the dataset\n",
    "    :param c_epoch (int): the current epoch\n",
    "    :param t_epoch (int): the total number of epochs\n",
    "    :param device (torch.device): the device to carry out the training \n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    # setting the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    print (\"Training...\")\n",
    "    # Setting tqdm to show some information on the screen\n",
    "    with tqdm(total=len(data_loader), ascii=True, desc='Epoch {}/{}: '.format(c_epoch, t_epoch), ncols=100) as t:\n",
    "\n",
    "\n",
    "        # Variables to store the avg metrics\n",
    "        loss_avg = AVGMetrics()\n",
    "        acc_avg = AVGMetrics()\n",
    "\n",
    "        # Getting the data from the DataLoader generator\n",
    "        for batch, data in enumerate(data_loader, 0):\n",
    "\n",
    "\n",
    "            # In data we may have imgs, labels and extra info. If extra info is [], it means we don't have it\n",
    "            # for the this training case. Imgs came in data[0], labels in data[1] and extra info in data[2]\n",
    "            try:\n",
    "                imgs_batch, labels_batch, metadata_batch, _ = data\n",
    "            except ValueError:\n",
    "                imgs_batch, labels_batch = data\n",
    "                metadata_batch = []\n",
    "\n",
    "            if len(metadata_batch):\n",
    "                # In this case we have extra information and we need to pass this data to the model\n",
    "                # Moving the data to the deviced that we set above\n",
    "                imgs_batch, labels_batch = imgs_batch.to(device), labels_batch.to(device)\n",
    "                metadata_batch = metadata_batch.to(device)\n",
    "                metadata_batch = metadata_batch.float()\n",
    "\n",
    "                # Doing the forward pass\n",
    "                out = model(imgs_batch, metadata_batch)\n",
    "            else:\n",
    "                # In this case we don't have extra info, so the model doesn't expect for it\n",
    "                # Moving the data to the deviced that we set above\n",
    "                imgs_batch, labels_batch = imgs_batch.to(device), labels_batch.to(device)\n",
    "\n",
    "                # Doing the forward pass\n",
    "                out = model(imgs_batch)\n",
    "\n",
    "            # Computing loss function\n",
    "            loss = loss_fn(out, labels_batch)\n",
    "\n",
    "            # Computing the accuracy\n",
    "            acc = accuracy(out, labels_batch)\n",
    "\n",
    "            # Getting the avg metrics\n",
    "            loss_avg.update(loss.item())\n",
    "            acc_avg.update(acc.item())\n",
    "\n",
    "            # Zero the parameters gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Computing gradients and performing the update step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Updating tqdm\n",
    "            t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
    "            t.update()\n",
    "\n",
    "    return {\"loss\": loss_avg(), \"accuracy\": acc_avg()}\n",
    "\n",
    "def fit_model (model, train_data_loader, val_data_loader, optimizer=None, loss_fn=None, epochs=1,\n",
    "               epochs_early_stop=None, save_folder=None, initial_model=None, best_metric=\"loss\", device=None,\n",
    "               schedule_lr=None, config_bot=None, model_name=\"CNN\", resume_train=False, history_plot=True,\n",
    "               val_metrics=('accuracy'), metric_early_stop=None):\n",
    "    \"\"\"\n",
    "    This is the main function to carry out the training phase.\n",
    "\n",
    "    :param c_epoch (int): the current epoch\n",
    "    :param t_epoch (int): the total number of epochs\n",
    "    :param device (torch.device): the device to carry out the training\n",
    "    :param model (torch.nn.Module): a module to be trained\n",
    "    :param train_data_loader (torch.utils.DataLoader): a dataloader containing the start dataset\n",
    "    :param val_data_loader (torch.utils.DataLoader): a dataloader containing the validation dataset\n",
    "    :param optimizer (torch.optim.optim, optional): an optimizer to fit the model. If None, it will use the\n",
    "     optim.Adam(model.parameters(), lr=0.001). Default is None.\n",
    "    :param loss_fn (torch.nn.Loss, optional): a loss function to evaluate the model prediction. If None, it will use the\n",
    "    nn.CrossEntropyLoss(). Default is None.\n",
    "    :param epochs (int, optional): the number of epochs to start the model. Default is 10.\n",
    "    :param epochs_early_stop (int, optional): if you'd like to check early stop, pass the number of epochs that need to\n",
    "    be achieved to stop the training. It checks if the loss is improving. If it doesn't improve for epochs_early_stop,\n",
    "    training stops. If None, the training is never stopped. Default is None.\n",
    "    :param save_folder (string, optional): if you'd like to save the last and best checkpoints, just pass the folder\n",
    "    path in which the checkpoint will be saved. If None, the model is not saved in the disk. Default is None.\n",
    "    :param initial_model (string, optinal): if you'd like to restart the training from a given saved checkpoint, pass\n",
    "    the path to this file here. If None, the model starts training from scratch. Default is None.\n",
    "    :param resume_train (bool, optional): if you'd like to resume the training using the last values for optimizer and\n",
    "    starting from the last epoch trained, set it True. Default is False.\n",
    "    :param class_names (list, optional): the list of class names.\n",
    "    :param best_metric (string, optional): if you chose save the model, you can inform the metric you'd like to save as\n",
    "    the best. Default is loss.\n",
    "    :param device (torch.device): the device you'd like to start the model. If None, it will check if you have a GPU\n",
    "    available. If not, it use the CPU. Default is None.\n",
    "    :param topk: number of top accuracies to compute\n",
    "    :param schedule_lr (bool, optional): If you're using a schedule for the learning rate you need to pass it using this\n",
    "    variable. If this is None, no schdule will be performed. Default is None.\n",
    "    :param config_bot (string or dictionary, optional): this is a string containing the chat_id for the bot or a dict\n",
    "    containing the chat_id and the token, example: {chat_id: xxx, token: yyy}. If None, the chat_bot will not be used.\n",
    "    Default is None.\n",
    "    :param model_name (string, optional): this is the model's name, ex: ResNet. Defaul is CNN.\n",
    "    \"\"\"\n",
    "\n",
    "    logger = _config_logger(save_folder, model_name)\n",
    "    logger.info(\"Starting the training phase\")\n",
    "\n",
    "    if epochs_early_stop is not None:\n",
    "        logger.info('Early stopping is set using the number of epochs without improvement')\n",
    "    if metric_early_stop is not None:\n",
    "        logger.info('Early stopping is set using the min/max metric as threshold')\n",
    "    if epochs_early_stop is None and metric_early_stop is None:\n",
    "        logger.info('No early stopping is set')\n",
    "\n",
    "    history = TrainHistory()\n",
    "\n",
    "    # Checking if we have a saved model. If we have, load it, otherwise, let's start the model from scratch\n",
    "    epoch_resume = 0\n",
    "    if initial_model is not None:\n",
    "        logger.info(\"Loading the saved model in {} folder\".format(initial_model))\n",
    "\n",
    "        if resume_train:\n",
    "            model, optimizer, loss_fn, epoch_resume = load_model(initial_model, model)\n",
    "            logger.info(\"Resuming the training from epoch {} ...\".format(epoch_resume))\n",
    "        else:\n",
    "            model = load_model(initial_model, model)\n",
    "\n",
    "    else:\n",
    "        logger.info(\"The model will be trained from scratch\")\n",
    "\n",
    "\n",
    "    # Setting the device(s)\n",
    "    # If GPU is available, let's move the model to there. If you have more than one, let's use them!\n",
    "    \"\"\"\n",
    "    m_gpu = 0\n",
    "    if device is None:\n",
    "        if torch.cuda.is_available():\n",
    "\n",
    "            device = torch.device(\"cuda\")\n",
    "            # device = torch.device(\"cuda:\" + str(torch.cuda.current_device()))\n",
    "            m_gpu = torch.cuda.device_count()\n",
    "            if m_gpu > 1:\n",
    "                logger.info(\"The training will be carry out using {} GPUs:\".format(m_gpu))\n",
    "                for g in range(m_gpu):\n",
    "                    logger.info(torch.cuda.get_device_name(g))\n",
    "\n",
    "                model = nn.DataParallel(model)\n",
    "            else:\n",
    "                logger.info(\"The training will be carry out using 1 GPU:\")\n",
    "                logger.info(torch.cuda.get_device_name(0))\n",
    "        else:\n",
    "            logger.info(\"The training will be carry out using CPU\")\n",
    "            device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        logger.info(\"The training will be carry out using 1 GPU:\")\n",
    "        logger.info(torch.cuda.get_device_name(device))\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    # Moving the model to the given device\n",
    "    model.to(device)\n",
    "\n",
    "    # Setting data to store the best mestric\n",
    "    logging.info(\"The best metric to get the best model will be {}\".format(best_metric))\n",
    "    if best_metric == 'loss':\n",
    "        best_metric_value = 1000\n",
    "    else:\n",
    "        best_metric_value = 0\n",
    "    best_flag = False\n",
    "\n",
    "    # Checking if we need to compute the balanced accuracy\n",
    "    if val_metrics is None:\n",
    "        get_bal_acc = False\n",
    "    else:\n",
    "        get_bal_acc = 'balanced_accuracy' in val_metrics\n",
    "\n",
    "    # setting a flag for the early stop\n",
    "    early_stop_count = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    # writer is used to generate the summary files to be loaded at tensorboard\n",
    "    writer = SummaryWriter (os.path.join(save_folder, 'summaries'))\n",
    "\n",
    "    \n",
    "    # Let's iterate for `epoch` epochs or a tolerance.\n",
    "    # It always start from epoch resume. If it's set, it starts from the last epoch the training phase was stopped,\n",
    "    # otherwise, it starts from 0\n",
    "    epoch = epoch_resume\n",
    "    while epoch < epochs:\n",
    "\n",
    "        # Updating epoch\n",
    "        epoch += 1\n",
    "\n",
    "        # Training and getting the metrics for one epoch\n",
    "        train_metrics = _train_epoch(model, optimizer, loss_fn, train_data_loader, epochs, device)\n",
    "\n",
    "        # After each epoch, we evaluate the model for the training and validation data\n",
    "        val_metrics = metrics_for_eval (model, val_data_loader, device, loss_fn)\n",
    "\n",
    "        # Checking the schedule if applicable\n",
    "        if isinstance(schedule_lr, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            schedule_lr.step(best_metric_value)\n",
    "        elif isinstance(schedule_lr, torch.optim.lr_scheduler.MultiStepLR):\n",
    "            schedule_lr.step(epoch)\n",
    "\n",
    "        # Getting the current LR\n",
    "        current_LR = None\n",
    "        for param_group in optimizer.param_groups:\n",
    "            current_LR = param_group['lr']\n",
    "\n",
    "\n",
    "        writer.add_scalars('Loss', {'val-loss': val_metrics['loss'],\n",
    "                                                 'start-loss': train_metrics['loss']},\n",
    "                                                 epoch)\n",
    "\n",
    "        writer.add_scalars('Accuracy', {'val-loss': val_metrics['accuracy'],\n",
    "                                    'start-loss': train_metrics['accuracy']},\n",
    "                                    epoch)\n",
    "\n",
    "        history.update(train_metrics['loss'], val_metrics['loss'], train_metrics['accuracy'], val_metrics['accuracy'])\n",
    "\n",
    "\n",
    "        # Getting the metrics for the training partition epoch\n",
    "        train_print = \"-- Loss: {:.3f}\\n-- Acc: {:.3f}\\n\".format(train_metrics[\"loss\"],train_metrics[\"accuracy\"])\n",
    "\n",
    "        # Getting the metrics for the validation partition in this epoch\n",
    "        val_print = \"-- Loss: {:.3f}\\n-- Acc: {:.3f}\\n\".format(val_metrics[\"loss\"],val_metrics[\"accuracy\"])\n",
    "\n",
    "        early_stop_count += 1\n",
    "        new_best_print = None\n",
    "        # Defining the best metric for validation\n",
    "        if best_metric == 'loss':\n",
    "            if val_metrics[best_metric] <= best_metric_value:\n",
    "                best_metric_value = val_metrics[best_metric]\n",
    "                new_best_print = '\\n-- New best {}: {:.3f}'.format(best_metric, best_metric_value)\n",
    "                best_flag = True\n",
    "                best_epoch = epoch\n",
    "                early_stop_count = 0\n",
    "        else:\n",
    "            if val_metrics[best_metric] >= best_metric_value:\n",
    "                best_metric_value = val_metrics[best_metric]\n",
    "                new_best_print = '\\-- New best {}: {:.3f}'.format(best_metric, best_metric_value)\n",
    "                best_flag = True\n",
    "                best_epoch = epoch\n",
    "                early_stop_count = 0\n",
    "\n",
    "        # Check if it's the best model in order to save it\n",
    "        if save_folder is not None:\n",
    "            save_model(model, save_folder, epoch, optimizer, loss_fn, best_flag)\n",
    "        best_flag = False\n",
    "\n",
    "        # Updating the logger\n",
    "        msg = \"Metrics for epoch {} out of {}\\n\".format(epoch, epochs)\n",
    "        msg += \"- Train\\n\"\n",
    "        msg += train_print + \"\\n\"\n",
    "        msg += \"\\n- Validation\\n\"\n",
    "        msg += val_print + \"\\n\"\n",
    "        msg += \"\\n- Training info\"\n",
    "        msg += \"\\n-- Early stopping counting: {} max to stop is {}\".format(early_stop_count, epochs_early_stop)\n",
    "        msg += \"\\n-- Current LR: {}\".format(current_LR)\n",
    "        if new_best_print is not None:\n",
    "            msg += new_best_print\n",
    "        msg += \"\\n-- Best {} so far: {:.3f} on epoch {}\\n\".format(best_metric, best_metric_value, best_epoch)\n",
    "\n",
    "        # Checking the early stop\n",
    "        if epochs_early_stop is not None:\n",
    "            if early_stop_count >= epochs_early_stop:\n",
    "                logger.info(msg)\n",
    "                logger.info(\"The early stop trigger was activated. The validation {} \" .format(best_metric) +\n",
    "                            \"{:.3f} did not improved for {} epochs.\".format(best_metric_value,\n",
    "                                                                            epochs_early_stop) +\n",
    "                            \"The training phase was stopped.\")\n",
    "\n",
    "                break\n",
    "\n",
    "        # Checking the early stop\n",
    "        if metric_early_stop is not None:\n",
    "            stop = False\n",
    "            if best_metric == 'loss':\n",
    "                if metric_early_stop >= best_metric_value:\n",
    "                    stop = True\n",
    "            else:\n",
    "                if metric_early_stop <= best_metric_value:\n",
    "                    stop = True\n",
    "\n",
    "            if stop:\n",
    "                logger.info(msg)\n",
    "                logger.info(\"The early stop trigger was activated. The validation {} \".format(best_metric) +\n",
    "                            \"{:.3f} achieved the defined threshold {:.3f}.\".format(best_metric_value,\n",
    "                                                                            metric_early_stop) +\n",
    "                            \"The training phase was stopped.\")\n",
    "                break\n",
    "\n",
    "        # Sending all message to the logger\n",
    "        logger.info(msg)\n",
    "\n",
    "\n",
    "    if history_plot:\n",
    "        history.save_plot(save_folder)\n",
    "\n",
    "    history.save(save_folder)\n",
    "    print('\\n')\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_for_eval (model, data_loader, device, loss_fn):\n",
    "    \"\"\"\n",
    "        This function returns accuracy and loss for the evaluation partition\n",
    "\n",
    "        :param model (nn.Model): the model you' want to evaluate\n",
    "        :param data_loader (DataLoader): the DataLoader containing the data partition\n",
    "        :param checkpoint_path(string, optional): string with a checkpoint to load the model. If None, none checkpoint is\n",
    "        loaded. Default is None.\n",
    "        :param loss_fn (nn.Loss): the loss function used in the training\n",
    "        :return: a instance of the classe metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # setting the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    print (\"\\nEvaluating...\")\n",
    "    # Setting tqdm to show some information on the screen\n",
    "    \n",
    "    with tqdm(total=len(data_loader), ascii=True, ncols=100) as t:\n",
    "\n",
    "        # Setting require_grad=False in order to dimiss the gradient computation in the graph\n",
    "        with torch.no_grad():\n",
    "\n",
    "            loss_avg = AVGMetrics()\n",
    "            acc_avg = AVGMetrics()\n",
    "\n",
    "\n",
    "            for data in data_loader:\n",
    "\n",
    "                # In data we may have imgs, labels and extra info. If extra info is [], it means we don't have it\n",
    "                # for the this training case. Imgs came in data[0], labels in data[1] and extra info in data[2]\n",
    "                try:\n",
    "                    images_batch, labels_batch, meta_data_batch, _ = data\n",
    "                except ValueError:\n",
    "                    images_batch, labels_batch = data\n",
    "                    meta_data_batch = []\n",
    "\n",
    "                if len(meta_data_batch):\n",
    "                    # Moving the data to the deviced that we set above\n",
    "                    images_batch, labels_batch = images_batch.to(device), labels_batch.to(device)\n",
    "                    meta_data_batch = meta_data_batch.to(device)\n",
    "                    meta_data_batch = meta_data_batch.float()\n",
    "\n",
    "                    # Doing the forward pass using meta_data\n",
    "                    pred_batch = model(images_batch, meta_data_batch)\n",
    "                else:\n",
    "                    # Moving the data to the device that we set above\n",
    "                    images_batch, labels_batch = images_batch.to(device), labels_batch.to(device)\n",
    "\n",
    "                    # Doing the forward pass without using meta-data\n",
    "                    pred_batch = model(images_batch)\n",
    "\n",
    "                # Computing the loss\n",
    "                L = loss_fn(pred_batch, labels_batch)\n",
    "                # Computing the accuracy\n",
    "                acc  = accuracy(pred_batch, labels_batch)\n",
    "\n",
    "                loss_avg.update(L.item())\n",
    "                acc_avg.update(acc.item())\n",
    "\n",
    "                if Metrics is not None:\n",
    "                    try:\n",
    "                        images_batch, labels_batch, meta_data_batch, _ = data\n",
    "                    except ValueError:\n",
    "                        images_batch, labels_batch = data\n",
    "                        meta_data_batch = []\n",
    "\n",
    "                if len(meta_data_batch):\n",
    "                    # Moving the data to the deviced that we set above\n",
    "                    images_batch, labels_batch = images_batch.to(device), labels_batch.to(device)\n",
    "                    meta_data_batch = meta_data_batch.to(device)\n",
    "                    meta_data_batch = meta_data_batch.float()\n",
    "\n",
    "                    # Doing the forward pass using meta_data\n",
    "                    pred_batch = model(images_batch, meta_data_batch)\n",
    "                else:\n",
    "                    # Moving the data to the device that we set above\n",
    "                    images_batch, labels_batch = images_batch.to(device), labels_batch.to(device)\n",
    "\n",
    "                    # Doing the forward pass without using meta-data\n",
    "                    pred_batch = model(images_batch)\n",
    "\n",
    "                    # Moving the data to CPU and converting it to numpy in order to compute the metrics\n",
    "                    pred_batch_np = nnF.softmax(pred_batch, dim=1).cpu().numpy()\n",
    "                    labels_batch_np = labels_batch.cpu().numpy()\n",
    "                    # updating the scores\n",
    "                    Metrics.update_scores(labels_batch_np, pred_batch_np)\n",
    "\n",
    "                # Updating tqdm\n",
    "                t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
    "                t.update()\n",
    "\n",
    "    return {\"loss\": loss_avg(), \"accuracy\": acc_avg()}\n",
    "\n",
    "\n",
    "# Testing the model\n",
    "def test_model (model, data_loader, checkpoint_path=None, loss_fn=None, device=None, save_pred=False,\n",
    "                    partition_name='Test', metrics_to_comp='all', class_names=None, metrics_options=None,\n",
    "                    apply_softmax=True, verbose=True, full_path_pred=None):\n",
    "    \"\"\"\n",
    "    This function evaluates a given model for a given data_loader\n",
    "\n",
    "    :param model (nn.Model): the model you'd like to evaluate\n",
    "    :param data_loader (DataLoader): the DataLoader containing the data partition\n",
    "    :param checkpoint_path(string, optional): string with a checkpoint to load the model. If None, no checkpoint is\n",
    "    loaded. Default is None.\n",
    "    :param loss_fn (nn.Loss): the loss function used in the training\n",
    "    :param partition_name (string): the partition name\n",
    "    :param metrics (list, tuple or string): it's the variable that receives the metrics you'd like to compute.\n",
    "        IMPORTANT: if metrics is None, only the prediction.csv will be generated. Default is only the accuracy.\n",
    "    :param class_names (list, tuple): a list or tuple containing the classes names in the same order you use in the\n",
    "        label. For ex: ['C1', 'C2']. For more information about the options, please, refers to\n",
    "        jedy.pytorch.model.metrics.py\n",
    "    :param metrics_ options (dict): this is a dict containing some options to compute the metrics. Default is None.\n",
    "    For more information about the options, please, refers to jedy.pytorch.model.metrics.py\n",
    "    :param device (torch.device, optional): the device to use. If None, the code will look for a device. Default is\n",
    "    None. For more information about the options, please, refers to jedy.pytorch.model.metrics.py\n",
    "    :param verbose (bool, optional): if you'd like to print information o the screen. Default is True\n",
    "    True. Default is False.\n",
    "\n",
    "    :return: a instance of the classe metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # setting the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    def _get_predictions (model, images_batch, meta_data_batch=None):        \n",
    "        with torch.no_grad():\n",
    "            if meta_data_batch is None:\n",
    "                pred_batch = model(images_batch)\n",
    "            else:\n",
    "                pred_batch = model(images_batch, meta_data_batch)\n",
    "        return pred_batch\n",
    "\n",
    "    if checkpoint_path is not None:\n",
    "        model = load_model(checkpoint_path, model)\n",
    "\n",
    "    if device is None:\n",
    "        # Setting the device\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda:\" + str(torch.cuda.current_device()))\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "\n",
    "    # Moving the model to the given device\n",
    "    model.to(device)\n",
    "\n",
    "    if loss_fn is None:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Setting the metrics object\n",
    "    metrics = Metrics (metrics_to_comp, class_names, metrics_options)\n",
    "\n",
    "    print(\"Testing...\")\n",
    "    # Setting tqdm to show some information on the screen\n",
    "    with tqdm(total=len(data_loader), ascii=True, ncols=100) as t:\n",
    "\n",
    "        loss_avg = AVGMetrics()\n",
    "        acc_avg = AVGMetrics()\n",
    "\n",
    "        for data in data_loader:\n",
    "            # In data we may have images, labels, meta-data, and image ID. If meta-data is [], it means we don't have it\n",
    "            # for the this training case. Images came in data[0], labels in data[1], meta_data in data[2], and image_id\n",
    "            # in data[3]\n",
    "            try:\n",
    "                images_batch, labels_batch, meta_data_batch, img_id = data\n",
    "            except ValueError:\n",
    "                images_batch, labels_batch = data\n",
    "                meta_data_batch = []\n",
    "                img_id = None\n",
    "\n",
    "            if len(meta_data_batch):\n",
    "                # Moving the data to the device that we set above\n",
    "                images_batch = images_batch.to(device)\n",
    "                if len(labels_batch):\n",
    "                    labels_batch = labels_batch.to(device)\n",
    "                meta_data_batch = meta_data_batch.to(device)\n",
    "                meta_data_batch = meta_data_batch.float()\n",
    "\n",
    "                # Doing the forward pass using meta-data\n",
    "                pred_batch = _get_predictions (model, images_batch, meta_data_batch)\n",
    "            elif len(labels_batch):\n",
    "                # Moving the data to the device that we set above\n",
    "                images_batch, labels_batch = images_batch.to(device), labels_batch.to(device)\n",
    "\n",
    "                # Doing the forward pass without using meta-data\n",
    "                pred_batch = _get_predictions(model, images_batch)\n",
    "            else:\n",
    "                # Moving the data to the deviced that we set above\n",
    "                images_batch = images_batch.to(device)\n",
    "\n",
    "                # Doing the forward pass without using meta_data\n",
    "                pred_batch = _get_predictions(model, images_batch)\n",
    "\n",
    "            # Computing the loss\n",
    "            if len(labels_batch):\n",
    "                L = loss_fn(pred_batch, labels_batch)\n",
    "                acc  = accuracy(pred_batch, labels_batch)\n",
    "                loss_avg.update(L.item())\n",
    "                acc_avg.update(acc.item())\n",
    "                \n",
    "                labels_batch_np = labels_batch.cpu().numpy()\n",
    "            else:\n",
    "                labels_batch_np = None\n",
    "                loss_avg.update(0)\n",
    "                acc_avg.update(0)\n",
    "\n",
    "            # Moving the data to CPU and converting it to numpy in order to compute the metrics\n",
    "            if apply_softmax:\n",
    "                pred_batch_np = nnF.softmax(pred_batch,dim=1).cpu().numpy()\n",
    "            else:\n",
    "                pred_batch_np = pred_batch.cpu().numpy()\n",
    "\n",
    "            # updating the scores\n",
    "            metrics.update_scores(labels_batch_np, pred_batch_np, img_id)\n",
    "\n",
    "            # Updating tqdm\n",
    "            if metrics.metrics_names is None:\n",
    "                t.set_postfix(loss='{:05.3f}'.format(0.0))\n",
    "                t.set_postfix(accuracy='{:05.3f}'.format(0.0))\n",
    "            else:\n",
    "                t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
    "                #t.set_postfix(accuracy='{:05.3f}'.format(acc_avg()))\n",
    "\n",
    "            t.update()\n",
    "\n",
    "    # Adding loss into the metric values\n",
    "    metrics.add_metric_value(\"loss\", loss_avg())\n",
    "\n",
    "    # Getting the metrics\n",
    "    metrics.compute_metrics()\n",
    "\n",
    "    if save_pred or metrics.metrics_names is None:\n",
    "        if full_path_pred is None:\n",
    "            metrics.save_scores()\n",
    "        else:\n",
    "            _spt = full_path_pred.split('/')\n",
    "            _folder = \"/\".join(_spt[0:-1])\n",
    "            _p = _spt[-1]\n",
    "            metrics.save_scores(folder_path=_folder, pred_name=_p)\n",
    "\n",
    "    if verbose:\n",
    "        print('- {} metrics:'.format(partition_name))\n",
    "        metrics.print()\n",
    "\n",
    "\n",
    "    return metrics.metrics_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 1\n",
    "BASE_PATH = \"E:/Skin_App/Drive\"\n",
    "csv_path_train = os.path.join(BASE_PATH, \"ked_parsed_train.csv\")\n",
    "imgs_folder_train = os.path.join(BASE_PATH, \"Images\")\n",
    "\n",
    "csv_path_test = os.path.join(BASE_PATH, \"ked_parsed_test.csv\")\n",
    "imgs_folder_test = os.path.join(BASE_PATH, \"Images\")\n",
    "\n",
    "use_meta_data = True\n",
    "comb_method = 'concat'\n",
    "comb_config = 20\n",
    "batch_size = 32\n",
    "epochs = 70\n",
    "\n",
    "    # Training variables\n",
    "best_metric = \"loss\"\n",
    "pretrained = True\n",
    "lr_init = 0.001\n",
    "sched_factor = 0.1\n",
    "sched_min_lr = 0.00001\n",
    "sched_patience = 5\n",
    "early_stop = 10\n",
    "weights = \"frequency\"\n",
    "\n",
    "model_name = 'mobilenet'\n",
    "save_folder = \"Results/\" + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main (folder,csv_path_train, imgs_folder_train, csv_path_test, imgs_folder_test, lr_init, sched_factor,\n",
    "          sched_min_lr, sched_patience, batch_size, epochs, early_stop, weights, model_name, pretrained,\n",
    "          save_folder, best_metric,comb_method, comb_config, use_meta_data):\n",
    "\n",
    "    meta_data_columns = ['Approximated_Age', 'F', 'M','Abdomain', 'Anterior_Torso','Armpit', 'Chin','Ear', 'Forehead', 'Lateral_Face',\n",
    "                         'Lower_Back', 'Lower_Extremity', 'Nail', 'Navel', 'Neck', 'Nose', 'Perioribital', 'Posterior_Torso', \n",
    "                         'Scalp', 'Upper_Extremity' ]\n",
    "    metric_options = {\n",
    "        'save_all_path': os.path.join(save_folder, \"best_metrics\"),\n",
    "        'pred_name_scores': 'predictions_best_test.csv',\n",
    "        'normalize_conf_matrix': True}\n",
    "    checkpoint_best = os.path.join(save_folder, 'best-checkpoint/best-checkpoint.pth')\n",
    "\n",
    "    # Loading the csv file\n",
    "    csv_all_folders = pd.read_csv(csv_path_train)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"- Loading validation data...\")\n",
    "    val_csv_folder = csv_all_folders[ (csv_all_folders['folder'] == folder) ]\n",
    "    train_csv_folder = csv_all_folders[ csv_all_folders['folder'] != folder ]\n",
    "\n",
    "    # Loading validation data\n",
    "    val_imgs_id = val_csv_folder['Image'].values\n",
    "    val_imgs_path = [\"{}/{}.jpg\".format(imgs_folder_train, Image) for Image in val_imgs_id]\n",
    "    val_labels = val_csv_folder['Diagnosis_number'].values\n",
    "    if use_meta_data:\n",
    "        val_meta_data = val_csv_folder[meta_data_columns].values\n",
    "        print(\"-- Using {} meta-data features\".format(len(meta_data_columns)))\n",
    "    else:\n",
    "        print(\"-- No metadata\")\n",
    "        val_meta_data = None\n",
    "    val_data_loader = get_data_loader (val_imgs_path, val_labels, val_meta_data, transform=ImgEvalTransform(),\n",
    "                                       batch_size=batch_size, shuf=True, num_workers=0, pin_memory=True)\n",
    "    print(\"-- Validation partition loaded with {} images\".format(len(val_data_loader)*batch_size))\n",
    "\n",
    "    print(\"- Loading training data...\")\n",
    "    train_imgs_id = train_csv_folder['Image'].values\n",
    "    train_imgs_path = [\"{}/{}.jpg\".format(imgs_folder_train, Image) for Image in train_imgs_id]\n",
    "    train_labels = train_csv_folder['Diagnosis_number'].values\n",
    "    if use_meta_data:\n",
    "        train_meta_data = train_csv_folder[meta_data_columns].values\n",
    "        print(\"-- Using {} meta-data features\".format(len(meta_data_columns)))\n",
    "    else:\n",
    "        print(\"-- No metadata\")\n",
    "        train_meta_data = None\n",
    "    train_data_loader = get_data_loader (train_imgs_path, train_labels, train_meta_data, transform=ImgTrainTransform(),\n",
    "                                       batch_size=batch_size, shuf=True, num_workers=0, pin_memory=True)\n",
    "    print(\"-- Training partition loaded with {} images\".format(len(train_data_loader)*batch_size))\n",
    "\n",
    "    print(\"-\"*50)\n",
    "    ####################################################################################################################\n",
    "\n",
    "    ser_lab_freq = get_labels_frequency(train_csv_folder, \"Diagnosis\", \"Image\")\n",
    "    labels_name = ser_lab_freq.index.values\n",
    "    freq = ser_lab_freq.values\n",
    "    ####################################################################################################################\n",
    "    print(\"- Loading\", model_name)\n",
    "\n",
    "    model = set_model(model_name, len(labels_name), comb_method=comb_method, \n",
    "                      comb_config=comb_config, pretrained=pretrained)\n",
    "    ####################################################################################################################\n",
    "    if weights == 'frequency':\n",
    "        weights = (freq.sum() / freq).round(3)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=torch.Tensor(weights))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr_init)\n",
    "    scheduler_lr = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=sched_factor, min_lr=sched_min_lr,\n",
    "                                                                    patience=sched_patience)\n",
    "    ####################################################################################################################\n",
    "\n",
    "    print(\"- Starting the training phase...\")\n",
    "    print(\"-\" * 50)\n",
    "    fit_model (model, train_data_loader, val_data_loader, optimizer=optimizer, loss_fn=loss_fn, epochs=epochs,\n",
    "               epochs_early_stop=early_stop, save_folder=save_folder, initial_model=None,\n",
    "               device=None, schedule_lr=scheduler_lr, config_bot=None, model_name=\"CNN\", resume_train=False,\n",
    "               history_plot=True, val_metrics=[\"accuracy\"], best_metric=best_metric)\n",
    "    # Testing the validation partition\n",
    "    print(\"- Evaluating the validation partition...\")\n",
    "    test_model (model, val_data_loader, checkpoint_path=checkpoint_best, loss_fn=loss_fn, save_pred=True,\n",
    "                partition_name='eval', metrics_to_comp=['accuracy'], class_names=labels_name, metrics_options=metric_options,\n",
    "                apply_softmax=True, verbose=False)\n",
    "\n",
    "    if csv_path_test is not None:\n",
    "        print(\"- Loading test data...\")\n",
    "        csv_test = pd.read_csv(csv_path_test)\n",
    "        \n",
    "        test_imgs_id = csv_test['Image'].values\n",
    "        test_imgs_path = [\"{}/{}.jpg\".format(imgs_folder_test, Image) for Image in test_imgs_id]\n",
    "        test_labels = csv_test['Diagnosis_number'].values\n",
    "        #csv_test['lateral torso'] = 0\n",
    "        if use_meta_data:\n",
    "            test_meta_data = csv_test[meta_data_columns].values\n",
    "            print(\"-- Using {} meta-data features\".format(len(meta_data_columns)))\n",
    "        else:\n",
    "            test_meta_data = None\n",
    "            print(\"-- No metadata\")\n",
    "\n",
    "        metric_options = {\n",
    "            'save_all_path': os.path.join(save_folder, \"best_metrics\"),\n",
    "            'pred_name_scores': 'predictions.csv',\n",
    "            'plot_conf_matrix': True,\n",
    "            'normalize_conf_matrix': True\n",
    "        }\n",
    "        test_data_loader = get_data_loader(test_imgs_path, test_labels, test_meta_data, transform=ImgEvalTransform(),\n",
    "                                           batch_size=batch_size, shuf=False, num_workers=0, pin_memory=True) \n",
    "        print(\"-- Testing partition loaded with {} images\".format(len(test_data_loader)*batch_size))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Testing the test partition\n",
    "        print(\"\\n- Evaluating the testing partition...\")\n",
    "        test_model(model, test_data_loader, checkpoint_path=None, metrics_to_comp='all', class_names=labels_name,\n",
    "                   metrics_options=metric_options, save_pred=True, verbose=False)\n",
    "    ####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\imgaug\\imgaug.py:184: DeprecationWarning: Function `Scale()` is deprecated. Use `Resize` instead. Resize has the exactly same interface as Scale.\n",
      "  warn_deprecated(msg, stacklevel=3)\n",
      "INFO:Train-Logger:Starting the training phase\n",
      "INFO:Train-Logger:Early stopping is set using the number of epochs without improvement\n",
      "INFO:Train-Logger:The model will be trained from scratch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "- Loading validation data...\n",
      "-- Using 20 meta-data features\n",
      "-- Validation partition loaded with 160 images\n",
      "- Loading training data...\n",
      "-- Using 20 meta-data features\n",
      "-- Training partition loaded with 1280 images\n",
      "--------------------------------------------------\n",
      "- Loading mobilenet\n",
      "- Starting the training phase...\n",
      "--------------------------------------------------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:14<00:00,  6.36s/it, loss=0.974]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:17<00:00,  3.54s/it, loss=1.127]\n",
      "INFO:Train-Logger:Metrics for epoch 1 out of 70\n",
      "- Train\n",
      "-- Loss: 0.974\n",
      "-- Acc: 0.621\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 1.127\n",
      "-- Acc: 0.653\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- New best loss: 1.127\n",
      "-- Best loss so far: 1.127 on epoch 1\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.49s/it, loss=0.706]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:17<00:00,  3.52s/it, loss=0.488]\n",
      "INFO:Train-Logger:Metrics for epoch 2 out of 70\n",
      "- Train\n",
      "-- Loss: 0.706\n",
      "-- Acc: 0.745\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.488\n",
      "-- Acc: 0.836\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- New best loss: 0.488\n",
      "-- Best loss so far: 0.488 on epoch 2\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.48s/it, loss=0.533]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:16<00:00,  3.20s/it, loss=0.578]\n",
      "INFO:Train-Logger:Metrics for epoch 3 out of 70\n",
      "- Train\n",
      "-- Loss: 0.533\n",
      "-- Acc: 0.801\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.578\n",
      "-- Acc: 0.810\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 1 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- Best loss so far: 0.488 on epoch 2\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.49s/it, loss=0.451]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.19s/it, loss=0.488]\n",
      "INFO:Train-Logger:Metrics for epoch 4 out of 70\n",
      "- Train\n",
      "-- Loss: 0.451\n",
      "-- Acc: 0.838\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.488\n",
      "-- Acc: 0.816\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- New best loss: 0.488\n",
      "-- Best loss so far: 0.488 on epoch 4\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:41<00:00,  5.53s/it, loss=0.432]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:16<00:00,  3.22s/it, loss=0.462]\n",
      "INFO:Train-Logger:Metrics for epoch 5 out of 70\n",
      "- Train\n",
      "-- Loss: 0.432\n",
      "-- Acc: 0.833\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.462\n",
      "-- Acc: 0.855\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- New best loss: 0.462\n",
      "-- Best loss so far: 0.462 on epoch 5\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.50s/it, loss=0.349]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.18s/it, loss=0.296]\n",
      "INFO:Train-Logger:Metrics for epoch 6 out of 70\n",
      "- Train\n",
      "-- Loss: 0.349\n",
      "-- Acc: 0.868\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.296\n",
      "-- Acc: 0.899\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- New best loss: 0.296\n",
      "-- Best loss so far: 0.296 on epoch 6\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:40<00:00,  5.50s/it, loss=0.338]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.16s/it, loss=0.315]\n",
      "INFO:Train-Logger:Metrics for epoch 7 out of 70\n",
      "- Train\n",
      "-- Loss: 0.338\n",
      "-- Acc: 0.867\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.315\n",
      "-- Acc: 0.874\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 1 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- Best loss so far: 0.296 on epoch 6\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:38<00:00,  5.47s/it, loss=0.344]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:16<00:00,  3.22s/it, loss=0.381]\n",
      "INFO:Train-Logger:Metrics for epoch 8 out of 70\n",
      "- Train\n",
      "-- Loss: 0.344\n",
      "-- Acc: 0.877\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.381\n",
      "-- Acc: 0.887\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 2 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- Best loss so far: 0.296 on epoch 6\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.48s/it, loss=0.329]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:16<00:00,  3.35s/it, loss=0.313]\n",
      "INFO:Train-Logger:Metrics for epoch 9 out of 70\n",
      "- Train\n",
      "-- Loss: 0.329\n",
      "-- Acc: 0.877\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.313\n",
      "-- Acc: 0.893\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 3 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- Best loss so far: 0.296 on epoch 6\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:41<00:00,  5.54s/it, loss=0.325]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.18s/it, loss=0.323]\n",
      "INFO:Train-Logger:Metrics for epoch 10 out of 70\n",
      "- Train\n",
      "-- Loss: 0.325\n",
      "-- Acc: 0.890\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.323\n",
      "-- Acc: 0.899\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 4 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- Best loss so far: 0.296 on epoch 6\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:40<00:00,  5.51s/it, loss=0.295]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.11s/it, loss=0.422]\n",
      "INFO:Train-Logger:Metrics for epoch 11 out of 70\n",
      "- Train\n",
      "-- Loss: 0.295\n",
      "-- Acc: 0.903\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.422\n",
      "-- Acc: 0.861\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 5 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- Best loss so far: 0.296 on epoch 6\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:43<00:00,  5.60s/it, loss=0.263]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:16<00:00,  3.33s/it, loss=0.374]\n",
      "INFO:Train-Logger:Metrics for epoch 12 out of 70\n",
      "- Train\n",
      "-- Loss: 0.263\n",
      "-- Acc: 0.895\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.374\n",
      "-- Acc: 0.861\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 6 max to stop is 10\n",
      "-- Current LR: 0.001\n",
      "-- Best loss so far: 0.296 on epoch 6\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:57<00:00,  5.93s/it, loss=0.295]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:16<00:00,  3.24s/it, loss=0.223]\n",
      "INFO:Train-Logger:Metrics for epoch 13 out of 70\n",
      "- Train\n",
      "-- Loss: 0.295\n",
      "-- Acc: 0.895\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.223\n",
      "-- Acc: 0.924\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.223\n",
      "-- Best loss so far: 0.223 on epoch 13\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:41<00:00,  5.53s/it, loss=0.210]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.16s/it, loss=0.202]\n",
      "INFO:Train-Logger:Metrics for epoch 14 out of 70\n",
      "- Train\n",
      "-- Loss: 0.210\n",
      "-- Acc: 0.927\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.202\n",
      "-- Acc: 0.924\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.202\n",
      "-- Best loss so far: 0.202 on epoch 14\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:41<00:00,  5.53s/it, loss=0.173]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:16<00:00,  3.26s/it, loss=0.186]\n",
      "INFO:Train-Logger:Metrics for epoch 15 out of 70\n",
      "- Train\n",
      "-- Loss: 0.173\n",
      "-- Acc: 0.945\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.186\n",
      "-- Acc: 0.935\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.186\n",
      "-- Best loss so far: 0.186 on epoch 15\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:41<00:00,  5.53s/it, loss=0.173]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.12s/it, loss=0.184]\n",
      "INFO:Train-Logger:Metrics for epoch 16 out of 70\n",
      "- Train\n",
      "-- Loss: 0.173\n",
      "-- Acc: 0.940\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.184\n",
      "-- Acc: 0.919\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.184\n",
      "-- Best loss so far: 0.184 on epoch 16\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:40<00:00,  5.51s/it, loss=0.146]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:16<00:00,  3.22s/it, loss=0.194]\n",
      "INFO:Train-Logger:Metrics for epoch 17 out of 70\n",
      "- Train\n",
      "-- Loss: 0.146\n",
      "-- Acc: 0.952\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.194\n",
      "-- Acc: 0.906\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 1 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.184 on epoch 16\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:40<00:00,  5.50s/it, loss=0.155]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.15s/it, loss=0.182]\n",
      "INFO:Train-Logger:Metrics for epoch 18 out of 70\n",
      "- Train\n",
      "-- Loss: 0.155\n",
      "-- Acc: 0.945\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.182\n",
      "-- Acc: 0.919\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.182\n",
      "-- Best loss so far: 0.182 on epoch 18\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.49s/it, loss=0.141]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.14s/it, loss=0.174]\n",
      "INFO:Train-Logger:Metrics for epoch 19 out of 70\n",
      "- Train\n",
      "-- Loss: 0.141\n",
      "-- Acc: 0.952\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.174\n",
      "-- Acc: 0.924\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.174\n",
      "-- Best loss so far: 0.174 on epoch 19\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.48s/it, loss=0.133]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.17s/it, loss=0.172]\n",
      "INFO:Train-Logger:Metrics for epoch 20 out of 70\n",
      "- Train\n",
      "-- Loss: 0.133\n",
      "-- Acc: 0.952\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.172\n",
      "-- Acc: 0.930\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.172\n",
      "-- Best loss so far: 0.172 on epoch 20\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.50s/it, loss=0.117]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.16s/it, loss=0.191]\n",
      "INFO:Train-Logger:Metrics for epoch 21 out of 70\n",
      "- Train\n",
      "-- Loss: 0.117\n",
      "-- Acc: 0.964\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.191\n",
      "-- Acc: 0.905\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 1 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.172 on epoch 20\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.49s/it, loss=0.116]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.15s/it, loss=0.182]\n",
      "INFO:Train-Logger:Metrics for epoch 22 out of 70\n",
      "- Train\n",
      "-- Loss: 0.116\n",
      "-- Acc: 0.958\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.182\n",
      "-- Acc: 0.924\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 2 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.172 on epoch 20\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.49s/it, loss=0.133]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.13s/it, loss=0.187]\n",
      "INFO:Train-Logger:Metrics for epoch 23 out of 70\n",
      "- Train\n",
      "-- Loss: 0.133\n",
      "-- Acc: 0.953\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.187\n",
      "-- Acc: 0.918\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 3 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.172 on epoch 20\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:40<00:00,  5.50s/it, loss=0.120]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.13s/it, loss=0.167]\n",
      "INFO:Train-Logger:Metrics for epoch 24 out of 70\n",
      "- Train\n",
      "-- Loss: 0.120\n",
      "-- Acc: 0.959\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.167\n",
      "-- Acc: 0.930\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.167\n",
      "-- Best loss so far: 0.167 on epoch 24\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.49s/it, loss=0.110]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.13s/it, loss=0.160]\n",
      "INFO:Train-Logger:Metrics for epoch 25 out of 70\n",
      "- Train\n",
      "-- Loss: 0.110\n",
      "-- Acc: 0.965\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.160\n",
      "-- Acc: 0.910\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.160\n",
      "-- Best loss so far: 0.160 on epoch 25\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:40<00:00,  5.50s/it, loss=0.133]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.15s/it, loss=0.151]\n",
      "INFO:Train-Logger:Metrics for epoch 26 out of 70\n",
      "- Train\n",
      "-- Loss: 0.133\n",
      "-- Acc: 0.950\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.151\n",
      "-- Acc: 0.931\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.151\n",
      "-- Best loss so far: 0.151 on epoch 26\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:38<00:00,  5.47s/it, loss=0.116]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.13s/it, loss=0.153]\n",
      "INFO:Train-Logger:Metrics for epoch 27 out of 70\n",
      "- Train\n",
      "-- Loss: 0.116\n",
      "-- Acc: 0.955\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.153\n",
      "-- Acc: 0.936\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 1 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.151 on epoch 26\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:38<00:00,  5.47s/it, loss=0.126]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.15s/it, loss=0.139]\n",
      "INFO:Train-Logger:Metrics for epoch 28 out of 70\n",
      "- Train\n",
      "-- Loss: 0.126\n",
      "-- Acc: 0.960\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.139\n",
      "-- Acc: 0.950\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.139\n",
      "-- Best loss so far: 0.139 on epoch 28\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.50s/it, loss=0.101]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.16s/it, loss=0.144]\n",
      "INFO:Train-Logger:Metrics for epoch 29 out of 70\n",
      "- Train\n",
      "-- Loss: 0.101\n",
      "-- Acc: 0.971\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.144\n",
      "-- Acc: 0.923\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 1 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.139 on epoch 28\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:39<00:00,  5.49s/it, loss=0.089]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.19s/it, loss=0.138]\n",
      "INFO:Train-Logger:Metrics for epoch 30 out of 70\n",
      "- Train\n",
      "-- Loss: 0.089\n",
      "-- Acc: 0.973\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.138\n",
      "-- Acc: 0.956\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.138\n",
      "-- Best loss so far: 0.138 on epoch 30\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:22<00:00,  6.57s/it, loss=0.087]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.81s/it, loss=0.135]\n",
      "INFO:Train-Logger:Metrics for epoch 31 out of 70\n",
      "- Train\n",
      "-- Loss: 0.087\n",
      "-- Acc: 0.972\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.135\n",
      "-- Acc: 0.943\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.135\n",
      "-- Best loss so far: 0.135 on epoch 31\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.69s/it, loss=0.098]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.80s/it, loss=0.120]\n",
      "INFO:Train-Logger:Metrics for epoch 32 out of 70\n",
      "- Train\n",
      "-- Loss: 0.098\n",
      "-- Acc: 0.964\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.120\n",
      "-- Acc: 0.943\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- New best loss: 0.120\n",
      "-- Best loss so far: 0.120 on epoch 32\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.68s/it, loss=0.080]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.85s/it, loss=0.143]\n",
      "INFO:Train-Logger:Metrics for epoch 33 out of 70\n",
      "- Train\n",
      "-- Loss: 0.080\n",
      "-- Acc: 0.973\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.143\n",
      "-- Acc: 0.937\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 1 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.120 on epoch 32\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:26<00:00,  6.67s/it, loss=0.087]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.85s/it, loss=0.144]\n",
      "INFO:Train-Logger:Metrics for epoch 34 out of 70\n",
      "- Train\n",
      "-- Loss: 0.087\n",
      "-- Acc: 0.968\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.144\n",
      "-- Acc: 0.930\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 2 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.120 on epoch 32\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.69s/it, loss=0.087]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.81s/it, loss=0.154]\n",
      "INFO:Train-Logger:Metrics for epoch 35 out of 70\n",
      "- Train\n",
      "-- Loss: 0.087\n",
      "-- Acc: 0.966\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.154\n",
      "-- Acc: 0.931\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 3 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.120 on epoch 32\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:26<00:00,  6.66s/it, loss=0.080]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.81s/it, loss=0.137]\n",
      "INFO:Train-Logger:Metrics for epoch 36 out of 70\n",
      "- Train\n",
      "-- Loss: 0.080\n",
      "-- Acc: 0.976\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.137\n",
      "-- Acc: 0.937\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 4 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.120 on epoch 32\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.70s/it, loss=0.072]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.80s/it, loss=0.133]\n",
      "INFO:Train-Logger:Metrics for epoch 37 out of 70\n",
      "- Train\n",
      "-- Loss: 0.072\n",
      "-- Acc: 0.975\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.133\n",
      "-- Acc: 0.949\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 5 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.120 on epoch 32\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.70s/it, loss=0.070]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.85s/it, loss=0.164]\n",
      "INFO:Train-Logger:Metrics for epoch 38 out of 70\n",
      "- Train\n",
      "-- Loss: 0.070\n",
      "-- Acc: 0.976\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.164\n",
      "-- Acc: 0.918\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 6 max to stop is 10\n",
      "-- Current LR: 0.0001\n",
      "-- Best loss so far: 0.120 on epoch 32\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:26<00:00,  6.67s/it, loss=0.084]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.83s/it, loss=0.123]\n",
      "INFO:Train-Logger:Metrics for epoch 39 out of 70\n",
      "- Train\n",
      "-- Loss: 0.084\n",
      "-- Acc: 0.973\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.123\n",
      "-- Acc: 0.950\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 7 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.120 on epoch 32\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.69s/it, loss=0.089]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.80s/it, loss=0.114]\n",
      "INFO:Train-Logger:Metrics for epoch 40 out of 70\n",
      "- Train\n",
      "-- Loss: 0.089\n",
      "-- Acc: 0.966\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.114\n",
      "-- Acc: 0.956\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- New best loss: 0.114\n",
      "-- Best loss so far: 0.114 on epoch 40\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:25<00:00,  6.65s/it, loss=0.066]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:18<00:00,  3.79s/it, loss=0.119]\n",
      "INFO:Train-Logger:Metrics for epoch 41 out of 70\n",
      "- Train\n",
      "-- Loss: 0.066\n",
      "-- Acc: 0.979\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.119\n",
      "-- Acc: 0.950\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 1 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.114 on epoch 40\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.68s/it, loss=0.068]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:18<00:00,  3.79s/it, loss=0.118]\n",
      "INFO:Train-Logger:Metrics for epoch 42 out of 70\n",
      "- Train\n",
      "-- Loss: 0.068\n",
      "-- Acc: 0.977\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.118\n",
      "-- Acc: 0.955\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 2 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.114 on epoch 40\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.68s/it, loss=0.075]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.85s/it, loss=0.113]\n",
      "INFO:Train-Logger:Metrics for epoch 43 out of 70\n",
      "- Train\n",
      "-- Loss: 0.075\n",
      "-- Acc: 0.977\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.113\n",
      "-- Acc: 0.956\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 0 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- New best loss: 0.113\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.69s/it, loss=0.071]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.91s/it, loss=0.130]\n",
      "INFO:Train-Logger:Metrics for epoch 44 out of 70\n",
      "- Train\n",
      "-- Loss: 0.071\n",
      "-- Acc: 0.974\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.130\n",
      "-- Acc: 0.936\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 1 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.68s/it, loss=0.080]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.82s/it, loss=0.124]\n",
      "INFO:Train-Logger:Metrics for epoch 45 out of 70\n",
      "- Train\n",
      "-- Loss: 0.080\n",
      "-- Acc: 0.974\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.124\n",
      "-- Acc: 0.943\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 2 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:26<00:00,  6.67s/it, loss=0.074]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.82s/it, loss=0.127]\n",
      "INFO:Train-Logger:Metrics for epoch 46 out of 70\n",
      "- Train\n",
      "-- Loss: 0.074\n",
      "-- Acc: 0.974\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.127\n",
      "-- Acc: 0.955\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 3 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:26<00:00,  6.67s/it, loss=0.059]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.81s/it, loss=0.125]\n",
      "INFO:Train-Logger:Metrics for epoch 47 out of 70\n",
      "- Train\n",
      "-- Loss: 0.059\n",
      "-- Acc: 0.984\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.125\n",
      "-- Acc: 0.943\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 4 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.69s/it, loss=0.078]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.87s/it, loss=0.124]\n",
      "INFO:Train-Logger:Metrics for epoch 48 out of 70\n",
      "- Train\n",
      "-- Loss: 0.078\n",
      "-- Acc: 0.970\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.124\n",
      "-- Acc: 0.955\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 5 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.69s/it, loss=0.074]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.82s/it, loss=0.122]\n",
      "INFO:Train-Logger:Metrics for epoch 49 out of 70\n",
      "- Train\n",
      "-- Loss: 0.074\n",
      "-- Acc: 0.975\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.122\n",
      "-- Acc: 0.943\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 6 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.69s/it, loss=0.059]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:19<00:00,  3.81s/it, loss=0.130]\n",
      "INFO:Train-Logger:Metrics for epoch 50 out of 70\n",
      "- Train\n",
      "-- Loss: 0.059\n",
      "-- Acc: 0.979\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.130\n",
      "-- Acc: 0.924\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 7 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [22:28<00:00, 33.72s/it, loss=0.064]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:28<00:00,  5.62s/it, loss=0.129]\n",
      "INFO:Train-Logger:Metrics for epoch 51 out of 70\n",
      "- Train\n",
      "-- Loss: 0.064\n",
      "-- Acc: 0.980\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.129\n",
      "-- Acc: 0.924\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 8 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [04:27<00:00,  6.68s/it, loss=0.074]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:16<00:00,  3.23s/it, loss=0.123]\n",
      "INFO:Train-Logger:Metrics for epoch 52 out of 70\n",
      "- Train\n",
      "-- Loss: 0.074\n",
      "-- Acc: 0.970\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.123\n",
      "-- Acc: 0.955\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 9 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "Epoch 70/None:   0%|                                                         | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/None: 100%|####################################| 40/40 [03:41<00:00,  5.53s/it, loss=0.069]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:16<00:00,  3.24s/it, loss=0.124]\n",
      "INFO:Train-Logger:Metrics for epoch 53 out of 70\n",
      "- Train\n",
      "-- Loss: 0.069\n",
      "-- Acc: 0.983\n",
      "\n",
      "\n",
      "- Validation\n",
      "-- Loss: 0.124\n",
      "-- Acc: 0.949\n",
      "\n",
      "\n",
      "- Training info\n",
      "-- Early stopping counting: 10 max to stop is 10\n",
      "-- Current LR: 1e-05\n",
      "-- Best loss so far: 0.113 on epoch 43\n",
      "\n",
      "INFO:Train-Logger:The early stop trigger was activated. The validation loss 0.113 did not improved for 10 epochs.The training phase was stopped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving history plots in Results/mobilenet\\history\n",
      "Saving history CSVs in Results/mobilenet\\history\n",
      "\n",
      "\n",
      "- Evaluating the validation partition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:15<00:00,  3.04s/it, loss=0.113]\n",
      "  0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the scores in Results/mobilenet\\best_metrics\n",
      "- Loading test data...\n",
      "-- Using 20 meta-data features\n",
      "-- Testing partition loaded with 160 images\n",
      "--------------------------------------------------\n",
      "\n",
      "- Evaluating the testing partition...\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################################| 5/5 [00:11<00:00,  2.33s/it, loss=0.200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the scores in Results/mobilenet\\best_metrics\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = main(folder = folder, csv_path_train = csv_path_train, imgs_folder_train = imgs_folder_train, csv_path_test = csv_path_test,\n",
    "         imgs_folder_test = imgs_folder_test, lr_init = lr_init ,sched_factor = sched_factor,\n",
    "         sched_min_lr = sched_min_lr, sched_patience = sched_patience , batch_size = batch_size, epochs = epochs,\n",
    "         early_stop = early_stop, weights = weights, model_name = model_name, pretrained= pretrained, \n",
    "         save_folder = save_folder, best_metric = best_metric,comb_method= comb_method, comb_config= comb_config,\n",
    "         use_meta_data = use_meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
